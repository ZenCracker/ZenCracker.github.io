<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>投资理财知识体系</title>
      <link href="/2019/07/07/%E6%8A%95%E8%B5%84%E7%90%86%E8%B4%A2/"/>
      <url>/2019/07/07/%E6%8A%95%E8%B5%84%E7%90%86%E8%B4%A2/</url>
      
        <content type="html"><![CDATA[<h2 id="Why"><a href="#Why" class="headerlink" title="Why"></a>Why</h2><p>理念篇</p><ul><li>《富爸爸穷爸爸》</li><li>《小狗钱钱》</li></ul><p>穷人和中产阶级为钱而工作，富人让钱为他工作。富人买入资产。穷人只有支出。中产阶级购买自以为是资产的负债。如何才能让自己成为富人，如何才能跑出赚更多花更多的老鼠赛跑呢？</p><p>思维模式篇</p><ul><li>多元思维《穷查理宝典》</li><li>概率思维《对赌》</li><li>逆向思维《邓普顿教你逆向投资》</li><li>财商培养《思考致富》</li></ul><p>查理·芒格提出多元思维模型，包括工程学的冗余备份模型，数学的复利模型，物理学和化学的临界点、倾覆力矩、自我催化模型，生物学的现代达尔文综合模型，以及心理学的认知误判模型，这些模型相互强化并极大地放大彼此效应的因素而发明的词组就是“lollapalooza效应”。不同于现代教育中强调专业的单一、独立性，芒格要求大家思考问题从多个角度考虑相互关系，这样才能看清事物的本质。</p><p>价值投资</p><ul><li>《聪明的投资者》</li><li>《投资最重要的事情》</li><li>《巴菲特之道》</li><li>《投资中最简单的事情》</li></ul><p>本杰明·格雷厄姆的著作《聪明的投资者》是价值投资的开山之作，里面提到的市场先生的比喻，股票价格围绕价值，股票是公司一部分的理念奠定了价值投资的基础。巴菲特在其之上发扬光大，专注于价格合理、持续成长的伟大公司，耐心长期持有获得了巨大成功。</p><p>经济规律</p><ul><li>《小岛经济学》</li><li>《债务危机》</li><li>《经济机器是如何运作的》- 视频</li></ul><p>经济是有周期的，有些周期比较短5-8年，所以很多人可以一生中会见到几次，如果稍加注意便能察觉出来；有些周期比较长例如75年，很多人一生也就会遇到一次，这个时候往往会惊慌失措。瑞·达利欧的《债务危机》和《经济机器是如何运作的》是解释经济运行规律的非常好的书籍，能够用非常简明的语言解释清楚非常复杂的事情，并且理清其中的本质。每一次债务危机都不会相同，但又都有很多相同之处，理解和分析过去的危机，能够帮助我们更好理解未来。</p><h2 id="What"><a href="#What" class="headerlink" title="What"></a>What</h2><p>小白入门</p><ul><li>《力哥说理财：小白理财入门必修课》</li><li>《好好赚钱》</li><li>《简七理财》</li></ul><p>投资品种</p><ul><li>《力哥说理财：手把手教你玩转基金》</li><li>《力哥说理财：玩转互联网金融》</li><li>《指数基金投资指南》</li></ul><p>理财投资的品类极其繁杂，债券、股票、黄金、商品期货、外汇、房产等等，其中债券、股票、房产对于普通投资人而言是占比最大的投资品种。巴菲特多次强调对于普通投资者，最好的投资对象就是股票指数基金，如何挑选合适的投资品种，评估个人风险承受能力对于最终的投资收益都至关重要。</p><h2 id="How"><a href="#How" class="headerlink" title="How"></a>How</h2><p>他山之石</p><ul><li>彼得·林奇：《彼得·林奇的成功投资》《战胜华尔街》</li><li>巴菲特：《巴菲特之道》《巴菲特致股东的信》</li><li>卡尔·伊坎：《华尔街之狼：金融之王卡尔·伊坎传》</li><li>邓普顿：《邓普顿教你逆向投资》</li></ul><p>投资实践</p><ul><li>资产配置：《傻瓜式投资》</li><li>终身收入：《钱：7步创造终身收入》</li><li>中国经验：《雪球投资》</li><li>漫步投资：《漫步华尔街》</li></ul><p>如何进行投资是个非常个性化的事情，首先需要了解自己投资理财的目标，分析自己的优势和能力圈，了解自己的风险承受能力。其次，做好资产配置，这个会对于最终收益产生非常大的影响。<br>从世界著名的投资人身上学到他们投资的方式和思维方式，可以很好的让你避免误入歧途，同时从他们身上也能获得内心平静的力量，无论牛市还是熊市都能保持平和的心态。</p>]]></content>
      
      
      <categories>
          
          <category> 文章摘要 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 文章摘要 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>什么是MySQL</title>
      <link href="/2018/07/07/%E4%BB%80%E4%B9%88%E6%98%AFMySQL/"/>
      <url>/2018/07/07/%E4%BB%80%E4%B9%88%E6%98%AFMySQL/</url>
      
        <content type="html"><![CDATA[<p>MySQL（官方发音为英语发音：/maɪ ˌɛskjuːˈɛl/ My S-Q-L，但也经常读作英语发音：/maɪ ˈsiːkwəl/ My Sequel）原本是一个开放源代码的关系数据库管理系统（DBMS），原开发者为瑞典的MySQL AB公司，该公司于2008年被昇阳微系统（Sun Microsystems）收购。2009年，甲骨文公司（Oracle）收购昇阳微系统公司，MySQL成为Oracle旗下产品。在本教程中，会让大家快速掌握MySQL的基本知识，并轻松使用MySQL数据库。</p><h4 id="MySQL-介绍"><a href="#MySQL-介绍" class="headerlink" title="MySQL 介绍"></a>MySQL 介绍</h4><p>MySQL在过去由于性能高、成本低、可靠性好，已经成为最流行的开源数据库，因此被广泛地应用在Internet上的中小型网站中，是最流行的关系型数据库管理系统，在WEB应用方面MySQL是最好的RDBMS(Relational Database Management System：关系数据库管理系统)应用软件之一。随着MySQL的不断成熟，它也逐渐用于更多大规模网站和应用，比如维基百科、Google和Facebook等网站。</p><p>但被甲骨文公司收购后，Oracle大幅调涨MySQL商业版的售价，且甲骨文公司不再支持另一个自由软件项目OpenSolaris的发展，因此导致自由软件社区们对于Oracle是否还会持续支持MySQL社区版（MySQL之中唯一的免费版本）有所隐忧，因此原先一些使用MySQL的开源软件逐渐转向其它的数据库。例如维基百科已于2013年正式宣布将从MySQL迁移到MariaDB数据库。MySQL的创始人麦克尔·维德纽斯以MySQL为基础，成立分支计划MariaDB。</p><h4 id="MySQL-发展历史"><a href="#MySQL-发展历史" class="headerlink" title="MySQL 发展历史"></a>MySQL 发展历史</h4><p>很多人以为MySQL是最近15年内才出现的数据库，其实MySQL数据库的历史可以追溯到1979年，那时 Bill Gates 退学没多久，微软公司也才刚刚起步，而Larry的Oracle公司也才成立不久。那时有一个天才程序员 Monty Widenius 用 BASIC 设计了一个报表工具，过了不久，又将此工具使用 C 语言重写，移植到 UNIX 平台，当时只是一个底层的面向报表存储引擎名叫Unireg。</p><ul><li>1985年，瑞典的几位志同道合小伙子(David Axmark、Allan Larsson 和Monty Widenius) 成立了一家公司，这就是MySQL AB 的前身。</li><li>1990年，TcX公司的客户中开始有人要求为他的API提供SQL支持。当时有人提议直接使用商用数据库，但是Monty觉得商用数据库的速度难以令人满意。于是，他直接借助于mSQL的代码，将它集成到自己的存储引擎中。令人失望的是，效果并不太令人满意，于是，Monty雄心大起，决心自己重写一个SQL支持。</li><li>1996年，MySQL 1.0发布，它只面向一小拨人，相当于内部发布。</li><li>1996年10月，MySQL 3.11.1发布(MySQL没有2.x版本)，最开始只提供Solaris下的二进制版本。一个月后，Linux版本出现了。</li><li>1999～2000年，MySQL AB公司在瑞典成立。Monty雇了几个人与Sleepycat合作，开发出了Berkeley DB引擎，因为BDB支持事务处理，所以MySQL从此开始支持事务处理了。</li><li>2003年12月，MySQL 5.0版本发布，提供了视图、存储过程等功能。</li><li>2008年1月16日，Sun（太阳微系统）正式收购MySQL。</li><li>2009年4月20日，甲骨文公司宣布以每股9.50美元，74亿美元的总额收购Sun电脑公司。</li><li>2010年12月，MySQL 5.5发布，其主要新特性包括半同步的复制及对SIGNAL/RESIGNAL的异常处理功能的支持，最重要的是InnoDB存储引擎终于变为当前MySQL的默认存储引擎。</li><li>2013年6月18日，甲骨文公司修改MySQL授权协议，移除了GPL。但随后有消息称这是一个bug。</li></ul><h4 id="MySQL-版本"><a href="#MySQL-版本" class="headerlink" title="MySQL 版本"></a>MySQL 版本</h4><p>MySQL针对不同的用户，分了社区版和企业服务器版，还提供一些其它版本，是属于MySQL相关工具。</p><ul><li>MySQL Community Server 社区版本，开源免费，但不提供官方技术支持。</li><li>MySQL Enterprise Edition 企业版本，需付费，可以试用30天。</li><li>MySQL Cluster 集群版，开源免费。可将几个MySQL Server封装成一个Server。</li><li>MySQL Cluster CGE 高级集群版，需付费。</li><li>MySQL Workbench（GUI TOOL）一款专为MySQL设计的ER/数据库建模工具。</li><li>MySQL Workbench是著名的数据库设计工具DBDesigner4的继任者。MySQL Workbench又分为两个版本，分别是社区版（MySQL Workbench OSS）、商用版（MySQL Workbench SE）。</li></ul><p>MySQL 版本命命机制由三个数字组成，例如mysql-5.6.33-osx10.11-x86_64.tar.gz</p><ul><li>第一个数字（5）主版本号：当你做了不兼容的 API 修改，</li><li>第二个数字（7）次版本号：当你做了向下兼容的功能性新增，合计，主要和次要的数字构成发布系列号。该系列号描述了稳定的特征集。</li><li>第三个数字（1）修订号：当你做了向下兼容的问题修正。这是一个新的bugfix释放增加。在大多数情况下，在一系列最新版本是最好的选择。<br>Github 上面有语义化版本标准, 开源仓库mojombo/semver，上面的版本命名大致是跟语义化版本标准差不多，你可以看语义化版本标准来学习版本名机制。通过语义化版本标准来理解MySQL版本命命机制。</li></ul><h4 id="MySQL-的优势"><a href="#MySQL-的优势" class="headerlink" title="MySQL 的优势"></a>MySQL 的优势</h4><ul><li>使用C和C++编写，并使用了多种编译器进行测试，保证源代码的可移植性。</li><li>支持AIX、BSDi、FreeBSD、HP-UX、Linux、Mac OS、Novell NetWare、NetBSD、OpenBSD、OS/2 Wrap、Solaris、Windows等多种操作系统。</li><li>为多种编程语言提供了API。这些编程语言包括C、C++、C#、VB.NET、Delphi、Eiffel、Java、Perl、PHP、Python、Ruby和Tcl等。</li><li>支持多线程，充分利用CPU资源，支持多用户。</li><li>优化的SQL查询算法，有效地提高查询速度。</li><li>既能够作为一个单独的应用程序在客户端服务器网络环境中运行，也能够作为一个程序库而嵌入到其他的软件中。</li><li>提供多语言支持，常见的编码如中文的GB 2312、BIG5、日文的Shift JIS等都可以用作数据表名和数据列名。</li><li>提供TCP/IP、ODBC和JDBC等多种数据库连接途径。</li><li>提供用于管理、检查、优化数据库操作的管理工具。</li><li>可以处理拥有上千万条记录的大型数据库。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SSH常用命令</title>
      <link href="/2018/07/07/SSH%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"/>
      <url>/2018/07/07/SSH%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</url>
      
        <content type="html"><![CDATA[<p>目录操作：</p><blockquote><p>rm -rf mydir /<em>删除mydir目录</em>/<br>cd mydir /<em>进入mydir目录</em>/<br>cd – /<em>回上一级目录</em>/<br>cd .. /<em>回父目录，中间有空格</em>/<br>cd ~ /<em>回根目录</em>/<br>mv tools tool /<em>把tools目录改名为tool </em>/<br>ln -s tool bac /<em>给tool目录创建名为bac的符号链接,最熟悉的应该就是FTP中www链接到public_html目录了</em>/<br>cp -a tool /home/deepvps/www /<em>把tool目录下所有文件复制到www目录下 </em>/</p></blockquote><p>文件操作：</p><blockquote><p>rm go.tar /<em> 删除go.tar文件 </em>/<br>find mt.cgi /<em> 查找文件名为mt.cgi的文件 </em>/<br>df –h /<em> 查看磁盘剩余空间,好像没这个必要，除非你太那个了 </em>/</p></blockquote><p>解压缩：</p><blockquote><p>tar xvf wordpress.tar /<em> 解压tar格式的文件 </em>/<br>tar -tvf myfile.tar /<em> 查看tar文件中包含的文件 </em>/</p><p>tar cf toole.tar tool /<em> 把tool目录打包为toole.tar文件 </em>/<br>tar cfz vpser.tar.gz tool /<em> 把tool目录打包且压缩为vpser.tar.gz文件，因为.tar文件几乎是没有压缩过的，MT的.tar.gz文件解压成.tar文件后差不多是10MB </em>/</p><p>tar jcvf /var/bak/<a href="http://www.tar.bz2" target="_blank" rel="noopener">www.tar.bz2</a> /var/www/ /<em>创建.tar.bz2文件，压缩率高</em>/<br>tar xjf <a href="http://www.tar.bz2" target="_blank" rel="noopener">www.tar.bz2</a> /<em>解压tar.bz2格式</em>/</p><p>gzip -d ge.tar.gz /<em> 解压.tar.gz文件为.tar文件 </em>/<br>unzip phpbb.zip /<em> 解压zip文件，windows下要压缩出一个.tar.gz格式的文件还是有点麻烦的 </em>/</p></blockquote><p>下载：</p><blockquote><p>wget <a href="http://soft.deepvps/web/nginx/nginx-0.8.0.tar.gz" target="_blank" rel="noopener">http://soft.deepvps/web/nginx/nginx-0.8.0.tar.gz</a><br>/<em>下载远程服务器上的文件到自己的服务器，连上传都省了，服务器不是100M就是1000M的带宽，下载一个2-3兆的MT还不是几十秒的事 </em>/<br>wget -c <a href="http://soft.deepvps/web/nginx/nginx-0.8.0.tar.gz" target="_blank" rel="noopener">http://soft.deepvps/web/nginx/nginx-0.8.0.tar.gz</a><br>/<em> 继续下载上次未下载完的文件 </em>/</p></blockquote><p>进程管理：</p><blockquote><p>ps -aux /<em>ps 进程状态查询命令</em>/</p></blockquote><p>ps命令输出字段的含义：</p><blockquote><p>[list]<br>[<em>]USER，进程所有者的用户名。<br>[</em>]PID，进程号，可以唯一标识该进程。<br>[<em>]%CPU，进程自最近一次刷新以来所占用的CPU时间和总时间的百分比。<br>[</em>]%MEM，进程使用内存的百分比。<br>[<em>]VSZ，进程使用的虚拟内存大小，以K为单位。<br>[</em>]RSS，进程占用的物理内存的总数量，以K为单位。<br>[<em>]TTY，进程相关的终端名。<br>[</em>]STAT，进程状态，用(R–运行或准备运行；S–睡眠状态；I–空闲；Z–冻结；D–不间断睡眠；W-进程没有驻留页；T停止或跟踪。)这些字母来表示。<br>[<em>]START，进程开始运行时间。<br>[</em>]TIME，进程使用的总CPU时间。<br>[*]COMMAND，被执行的命令行。<br>[/list]</p></blockquote><blockquote><p>ps -aux | grep nginx /<em>在所有进程中，查找nginx的进程</em>/<br>kill 1234 /<em>1234为进程ID，即ps -aux 中的PID</em>/<br>killall nginx /<em>killall 通过程序的名字，直接杀死所有进程，nginx为进程名</em>/</p></blockquote><p>Vim操作：</p><blockquote><p>移动类的：<br>h/j/k/l: 左/下/上/右　移一格<br>w : 向后词移动　（前面加数字移动多少个词）<br>b : 向前词移动　（前面加数字移动多少个词）<br>e : 向后移到词末<br>ge : 向前移到词末<br>$ <end> : 行末<br>0 <home> : 行首<br>tx : 向右查找本行的x并移到那儿（大写时向左）<br>33G : 移到文件的第33行<br>gg : 文件首行<br>G : 文件尾行<br>33% : 文件的33%处<br>H/M/L : 屏幕的首/中/尾行<br>zt/zz/zb : 当前行移到屏幕的首/中/底部</home></end></p></blockquote><p>跳转：</p><blockquote><p>” : 回到跳转来的地方<br>CTRL-O : 跳到一个 “较老” 的地方<br>CTRL-I <tab> : 则跳到一个 “较新” 的地方</tab></p></blockquote><p>查找：</p><blockquote><p>/ : 向下查找（后加关键字）<br>? : 向上查找（后加关键字）<br>n : 下一条符合的记录</p></blockquote><p>编辑：</p><blockquote><p>i : 转换到插入模式<br>x : 删除当前字符<br>. : 重复最后一次的修改操作(同PS里ctrl+f执行滤镜)<br>u : 撤销操作<br>CTRL-R : 重做<br>p : 将删除的字符插入到当前位置(put)</p></blockquote><p>退出保存：</p><blockquote><p>:q : 退出<br>:q! : 不保存退出<br>ZZ : 保存后退出<br>:e! : 放弃修改重新编辑</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>合并语句--MERGE</title>
      <link href="/2018/05/29/2018-05-29-index/"/>
      <url>/2018/05/29/2018-05-29-index/</url>
      
        <content type="html"><![CDATA[<p>1、语法说明</p><blockquote></blockquote><p>MERGE 语句具有按条件获取要更新或插入到表中的数据行，然后从一个或多个源头对表进行更新或者向表中插入行两方面的能力。它最经常被用在数据仓库中来移动大量的数据，但它的应用不仅限于数据仓库环境下。这个语句提供的一个很大的附加值在于你可以很方便地把多个操作结合成一个。如果你避免去做那些不是必须做的事情，响应的时间可能得到相应的改善。</p><blockquote></blockquote><p>简单的说 MERGE 语句就是用来合并 UPDATE 语句和 INSERT 语句的。通过 MERGE 语句，可根据一张表或子查询的连接条件对另外一张表进行查询，连接条件匹配上了就执行 UPDATE，无法匹配就执行 INSERT。这个语句仅需要一次全表扫描就完成了全部工作，执行效率要高于 INSERT + UPDATE。语法：</p><blockquote></blockquote><p>MERGE INTO target_table<br>USING {table/view/subquery}<br>ON(condition)<br>WHEN MATCHED THEN merge_update_clause<br>WHEN NOT MATCHED THEN merge_insert_clause;</p><p>1.1、UPDATE 和 INSERT 可以只出现一个</p><p>只出现 INSERT 的示例：</p><blockquote></blockquote><p>– 如果课程表中没有“计算机”这门课程则插入这门课程<br>MERGE INTO demo.t_course t1<br>USING(SELECT 1 cid,’计算机’ cname FROM DUAL) t2<br>ON(t1.course_id=t2.cid)<br>WHEN NOT MATCHED THEN<br>INSERT(t1.course_id,t1.course_name) VALUES(t2.cid,t2.cname); </p><p>只出现 UPDATE 的示例：</p><blockquote></blockquote><p>– 如果课程表中有“计算机”这门课程则将这门课程的备注改为“工科”<br>MERGE INTO demo.t_course t1<br>USING(SELECT 1 cid,’计算机’ cname FROM DUAL) t2<br>ON(t1.course_name=t2.cname)<br>WHEN MATCHED THEN<br>UPDATE SET t1.course_desc=’工科’;</p><p>1.2、UPDATE 后面还可以再跟 WHERE</p><blockquote><p>如果课程表中有多个名为“计算机”的课程，而实际上只需要把课程 ID 为 1 的课程备注改为“工科”，上文中只出现 UPDATE 的示例就有逻辑错误了。这种情况的正确示例：</p></blockquote><p>MERGE INTO demo.t_course t1<br>USING(SELECT 1 cid,’计算机’ cname FROM DUAL) t2<br>ON(t1.course_name=t2.cname)<br>WHEN MATCHED THEN<br>UPDATE SET t1.course_desc=’工科’ WHERE t1.course_id=1;</p><p>1.3、UPDATE 和 INSERT 同时出现</p><blockquote><p>如果研发一部有叫“大国”的人，就把他的岗位工资加 200，如果没有就把他添加到研发一部。示例：</p></blockquote><p>MERGE INTO demo.t_staff t1<br>USING(SELECT ‘010101’ dept_code,’大国’ staff_name FROM DUAL) t2<br>ON(t1.dept_code=t2.dept_code AND t1.staff_name=t2.staff_name)<br>WHEN MATCHED THEN<br>  UPDATE SET t1.post_salary=t1.post_salary+200<br>WHEN NOT MATCHED THEN<br>  INSERT(staff_name, dept_code, gender, birthday, edu_bg, base_salary, post_salary, post_code)<br>  VALUES(‘大国’,’010101’,1,TO_DATE(‘1992-01-15’,’yyyy-mm-dd’),2,2500,4000,’P50’);  </p><blockquote><p>假如说员工中没有叫“大国”的，所以第一次执行上面这条语句时，大国会被插入到研发一部；这时候研发一部就已经有“大国”了，如果再执行第二次，“大国”的岗位工资就会被修改成 4200 了。</p></blockquote><p>1.4、UPDATE 之后还可以再删除行</p><blockquote><p>如要把低工资的员工固定薪资上调 500，然后把工资依然低于 5000 的员工数据删除，示例：</p></blockquote><p>MERGE INTO demo.t_staff_salary t1<br>USING demo.t_staff_low t2<br>ON(t1.staff_id=t2.staff_id)<br>WHEN MATCHED THEN<br>UPDATE SET t1.fixed_salary=t1.fixed_salary+500<br>DELETE WHERE t1.fixed_salary&lt;5000;  </p><blockquote><p>这种语法有三个注意点，如下：</p></blockquote><blockquote><p>DELETE 必须和 UPDATE 同时出现，且 DELETE WHERE 必须在 UPDATE [WHERE] 之后。<br>DELETE 只能删除目标表数据，无法删除源表数据。如上例中只能删除 t1 表的数据，无法删除 t2 表的数据。<br>只有同时满足 ON、UPDATE 的 WHERE 以及 DELETE 的 WHERE 三个条件的记录会被删除。也就是说 DELETE 的作用范围仅为被 UPDATE 过的那些行。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL基础</title>
      <link href="/2018/05/07/MySQL%E5%9F%BA%E7%A1%80/"/>
      <url>/2018/05/07/MySQL%E5%9F%BA%E7%A1%80/</url>
      
        <content type="html"><![CDATA[<p>/<em> 启动MySQL </em>/<br>net start mysql</p><p>/<em> 连接与断开服务器 </em>/<br>mysql -h 地址 -P 端口 -u 用户名 -p 密码</p><p>/<em> 跳过权限验证登录MySQL </em>/<br>mysqld –skip-grant-tables<br>– 修改root密码<br>密码加密函数password()<br>update mysql.user set password=password(‘root’);</p><p>SHOW PROCESSLIST – 显示哪些线程正在运行<br>SHOW VARIABLES – </p><p>/<em> 数据库操作 </em>/ ——————<br>– 查看当前数据库<br> select database();<br>– 显示当前时间、用户名、数据库版本<br> select now(), user(), version();<br>– 创建库<br> create database[ if not exists] 数据库名 数据库选项<br> 数据库选项：<br> CHARACTER SET charset_name<br> COLLATE collation_name<br>– 查看已有库<br> show databases[ like ‘pattern’]<br>– 查看当前库信息<br> show create database 数据库名<br>– 修改库的选项信息<br> alter database 库名 选项信息<br>– 删除库<br> drop database[ if exists] 数据库名<br> 同时删除该数据库相关的目录及其目录内容</p><p>/<em> 表的操作 </em>/ ——————<br>– 创建表<br> create [temporary] table[ if not exists] [库名.]表名 ( 表的结构定义 )[ 表选项]<br> 每个字段必须有数据类型<br> 最后一个字段后不能有逗号<br> temporary 临时表，会话结束时表自动消失<br> 对于字段的定义：<br> 字段名 数据类型 [NOT NULL | NULL] [DEFAULT default_value] [AUTO_INCREMENT] [UNIQUE [KEY] | [PRIMARY] KEY] [COMMENT ‘string’]<br>– 表选项<br> – 字符集<br> CHARSET = charset_name<br> 如果表没有设定，则使用数据库字符集<br> – 存储引擎<br> ENGINE = engine_name<br> 表在管理数据时采用的不同的数据结构，结构不同会导致处理方式、提供的特性操作等不同<br> 常见的引擎：InnoDB MyISAM Memory/Heap BDB Merge Example CSV MaxDB Archive<br> 不同的引擎在保存表的结构和数据时采用不同的方式<br> MyISAM表文件含义：.frm表定义，.MYD表数据，.MYI表索引<br> InnoDB表文件含义：.frm表定义，表空间数据和日志文件<br> SHOW ENGINES – 显示存储引擎的状态信息<br> SHOW ENGINE 引擎名 {LOGS|STATUS} – 显示存储引擎的日志或状态信息<br> – 数据文件目录<br> DATA DIRECTORY = ‘目录’<br> – 索引文件目录<br> INDEX DIRECTORY = ‘目录’<br> – 表注释<br> COMMENT = ‘string’<br> – 分区选项<br> PARTITION BY … (详细见手册)<br>– 查看所有表<br> SHOW TABLES[ LIKE ‘pattern’]<br> SHOW TABLES FROM 表名<br>– 查看表机构<br> SHOW CREATE TABLE 表名 （信息更详细）<br> DESC 表名 / DESCRIBE 表名 / EXPLAIN 表名 / SHOW COLUMNS FROM 表名 [LIKE ‘PATTERN’]<br> SHOW TABLE STATUS [FROM db_name] [LIKE ‘pattern’]<br>– 修改表<br> – 修改表本身的选项<br> ALTER TABLE 表名 表的选项<br> EG: ALTER TABLE 表名 ENGINE=MYISAM;<br> – 对表进行重命名<br> RENAME TABLE 原表名 TO 新表名<br> RENAME TABLE 原表名 TO 库名.表名 （可将表移动到另一个数据库）<br> – RENAME可以交换两个表名<br> – 修改表的字段机构<br> ALTER TABLE 表名 操作名<br> – 操作名<br> ADD[ COLUMN] 字段名 – 增加字段<br> AFTER 字段名 – 表示增加在该字段名后面<br> FIRST – 表示增加在第一个<br> ADD PRIMARY KEY(字段名) – 创建主键<br> ADD UNIQUE [索引名] (字段名)– 创建唯一索引<br> ADD INDEX [索引名] (字段名) – 创建普通索引<br> ADD<br> DROP[ COLUMN] 字段名 – 删除字段<br> MODIFY[ COLUMN] 字段名 字段属性 – 支持对字段属性进行修改，不能修改字段名(所有原有属性也需写上)<br> CHANGE[ COLUMN] 原字段名 新字段名 字段属性 – 支持对字段名修改<br> DROP PRIMARY KEY – 删除主键(删除主键前需删除其AUTO_INCREMENT属性)<br> DROP INDEX 索引名 – 删除索引<br> DROP FOREIGN KEY 外键 – 删除外键</p><p>– 删除表<br> DROP TABLE[ IF EXISTS] 表名 …<br>– 清空表数据<br> TRUNCATE [TABLE] 表名<br>– 复制表结构<br> CREATE TABLE 表名 LIKE 要复制的表名<br>– 复制表结构和数据<br> CREATE TABLE 表名 [AS] SELECT * FROM 要复制的表名<br>– 检查表是否有错误<br> CHECK TABLE tbl_name [, tbl_name] … [option] …<br>– 优化表<br> OPTIMIZE [LOCAL | NO_WRITE_TO_BINLOG] TABLE tbl_name [, tbl_name] …<br>– 修复表<br> REPAIR [LOCAL | NO_WRITE_TO_BINLOG] TABLE tbl_name [, tbl_name] … [QUICK] [EXTENDED] [USE_FRM]<br>– 分析表<br> ANALYZE [LOCAL | NO_WRITE_TO_BINLOG] TABLE tbl_name [, tbl_name] …</p><p>/<em> 数据操作 </em>/ ——————<br>– 增<br> INSERT [INTO] 表名 [(字段列表)] VALUES (值列表)[, (值列表), …]<br> – 如果要插入的值列表包含所有字段并且顺序一致，则可以省略字段列表。<br> – 可同时插入多条数据记录！<br> REPLACE 与 INSERT 完全一样，可互换。<br> INSERT [INTO] 表名 SET 字段名=值[, 字段名=值, …]<br>– 查<br> SELECT 字段列表 FROM 表名[ 其他子句]<br> – 可来自多个表的多个字段<br> – 其他子句可以不使用<br> – 字段列表可以用*代替，表示所有字段<br>– 删<br> DELETE FROM 表名[ 删除条件子句]<br> 没有条件子句，则会删除全部<br>– 改<br> UPDATE 表名 SET 字段名=新值[, 字段名=新值] [更新条件]</p><p>/<em> 字符集编码 </em>/ ——————<br>– MySQL、数据库、表、字段均可设置编码<br>– 数据编码与客户端编码不需一致<br>SHOW VARIABLES LIKE ‘character_set_%’ – 查看所有字符集编码项<br> character_set_client 客户端向服务器发送数据时使用的编码<br> character_set_results 服务器端将结果返回给客户端所使用的编码<br> character_set_connection 连接层编码<br>SET 变量名 = 变量值<br> set character_set_client = gbk;<br> set character_set_results = gbk;<br> set character_set_connection = gbk;<br>SET NAMES GBK; – 相当于完成以上三个设置<br>– 校对集<br> 校对集用以排序<br> SHOW CHARACTER SET [LIKE ‘pattern’]/SHOW CHARSET [LIKE ‘pattern’] 查看所有字符集<br> SHOW COLLATION [LIKE ‘pattern’] 查看所有校对集<br> charset 字符集编码 设置字符集编码<br> collate 校对集编码 设置校对集编码</p><p>/<em> 数据类型（列类型） </em>/ ——————</p><ol><li><p>数值类型<br>– a. 整型 ———-<br>类型 字节 范围（有符号位）<br>tinyint 1字节 -128 ~ 127 无符号位：0 ~ 255<br>smallint 2字节 -32768 ~ 32767<br>mediumint 3字节 -8388608 ~ 8388607<br>int 4字节<br>bigint 8字节</p><p>int(M) M表示总位数</p><ul><li>默认存在符号位，unsigned 属性修改</li><li>显示宽度，如果某个数不够定义字段时设置的位数，则前面以0补填，zerofill 属性修改<br>例：int(5) 插入一个数’123’，补填后为’00123’</li><li>在满足要求的情况下，越小越好。</li><li>1表示bool值真，0表示bool值假。MySQL没有布尔类型，通过整型0和1表示。常用tinyint(1)表示布尔型。</li></ul></li></ol><p>– b. 浮点型 ———-<br> 类型 字节 范围<br> float(单精度) 4字节<br> double(双精度) 8字节<br> 浮点型既支持符号位 unsigned 属性，也支持显示宽度 zerofill 属性。<br> 不同于整型，前后均会补填0.<br> 定义浮点型时，需指定总位数和小数位数。<br> float(M, D) double(M, D)<br> M表示总位数，D表示小数位数。<br> M和D的大小会决定浮点数的范围。不同于整型的固定范围。<br> M既表示总位数（不包括小数点和正负号），也表示显示宽度（所有显示符号均包括）。<br> 支持科学计数法表示。<br> 浮点数表示近似值。</p><p>– c. 定点数 ———-<br> decimal – 可变长度<br> decimal(M, D) M也表示总位数，D表示小数位数。<br> 保存一个精确的数值，不会发生数据的改变，不同于浮点数的四舍五入。<br> 将浮点数转换为字符串来保存，每9位数字保存为4个字节。</p><ol start="2"><li>字符串类型<br>– a. char, varchar ———-<br>char 定长字符串，速度快，但浪费空间<br>varchar 变长字符串，速度慢，但节省空间<br>M表示能存储的最大长度，此长度是字符数，非字节数。<br>不同的编码，所占用的空间不同。<br>char,最多255个字符，与编码无关。<br>varchar,最多65535字符，与编码有关。<br>一条有效记录最大不能超过65535个字节。<br>utf8 最大为21844个字符，gbk 最大为32766个字符，latin1 最大为65532个字符<br>varchar 是变长的，需要利用存储空间保存 varchar 的长度，如果数据小于255个字节，则采用一个字节来保存长度，反之需要两个字节来保存。<br>varchar 的最大有效长度由最大行大小和使用的字符集确定。<br>最大有效长度是65532字节，因为在varchar存字符串时，第一个字节是空的，不存在任何数据，然后还需两个字节来存放字符串的长度，所以有效长度是64432-1-2=65532字节。<br>例：若一个表定义为 CREATE TABLE tb(c1 int, c2 char(30), c3 varchar(N)) charset=utf8; 问N的最大值是多少？ 答：(65535-1-2-4-30*3)/3</li></ol><p>– b. blob, text ———-<br> blob 二进制字符串（字节字符串）<br> tinyblob, blob, mediumblob, longblob<br> text 非二进制字符串（字符字符串）<br> tinytext, text, mediumtext, longtext<br> text 在定义时，不需要定义长度，也不会计算总长度。<br> text 类型在定义时，不可给default值</p><p>– c. binary, varbinary ———-<br> 类似于char和varchar，用于保存二进制字符串，也就是保存字节字符串而非字符字符串。<br> char, varchar, text 对应 binary, varbinary, blob.</p><ol start="3"><li>日期时间类型<br>一般用整型保存时间戳，因为PHP可以很方便的将时间戳进行格式化。<br>datetime 8字节 日期及时间 1000-01-01 00:00:00 到 9999-12-31 23:59:59<br>date 3字节 日期 1000-01-01 到 9999-12-31<br>timestamp 4字节 时间戳 19700101000000 到 2038-01-19 03:14:07<br>time 3字节 时间 -838:59:59 到 838:59:59<br>year 1字节 年份 1901 - 2155</li></ol><p>datetime “YYYY-MM-DD hh:mm:ss”<br>timestamp “YY-MM-DD hh:mm:ss”<br> “YYYYMMDDhhmmss”<br> “YYMMDDhhmmss”<br> YYYYMMDDhhmmss<br> YYMMDDhhmmss<br>date “YYYY-MM-DD”<br> “YY-MM-DD”<br> “YYYYMMDD”<br> “YYMMDD”<br> YYYYMMDD<br> YYMMDD<br>time “hh:mm:ss”<br> “hhmmss”<br> hhmmss<br>year “YYYY”<br> “YY”<br> YYYY<br> YY</p><ol start="4"><li>枚举和集合<br>– 枚举(enum) ———-<br>enum(val1, val2, val3…)<br>在已知的值中进行单选。最大数量为65535.<br>枚举值在保存时，以2个字节的整型(smallint)保存。每个枚举值，按保存的位置顺序，从1开始逐一递增。<br>表现为字符串类型，存储却是整型。<br>NULL值的索引是NULL。<br>空字符串错误值的索引值是0。</li></ol><p>– 集合（set） ———-<br>set(val1, val2, val3…)<br> create table tab ( gender set(‘男’, ‘女’, ‘无’) );<br> insert into tab values (‘男, 女’);<br> 最多可以有64个不同的成员。以bigint存储，共8个字节。采取位运算的形式。<br> 当创建表时，SET成员值的尾部空格将自动被删除。</p><p>/<em> 选择类型 </em>/<br>– PHP角度</p><ol><li>功能满足</li><li>存储空间尽量小，处理效率更高</li><li>考虑兼容问题</li></ol><p>– IP存储 ———-</p><ol><li>只需存储，可用字符串</li><li>如果需计算，查找等，可存储为4个字节的无符号int，即unsigned<br>1) PHP函数转换<br>ip2long可转换为整型，但会出现携带符号问题。需格式化为无符号的整型。<br>利用sprintf函数格式化字符串<br>sprintf(“%u”, ip2long(‘192.168.3.134’));<br>然后用long2ip将整型转回IP字符串<br>2) MySQL函数转换(无符号整型，UNSIGNED)<br>INET_ATON(‘127.0.0.1’) 将IP转为整型<br>INET_NTOA(2130706433) 将整型转为IP</li></ol><p>/<em> 列属性（列约束） </em>/ ——————</p><ol><li><p>主键</p><ul><li>能唯一标识记录的字段，可以作为主键。</li><li>一个表只能有一个主键。</li><li>主键具有唯一性。</li><li>声明字段时，用 primary key 标识。<br>也可以在字段列表之后声明<br>例：create table tab ( id int, stu varchar(10), primary key (id));</li><li>主键字段的值不能为null。</li><li>主键可以由多个字段共同组成。此时需要在字段列表后声明的方法。<br>例：create table tab ( id int, stu varchar(10), age int, primary key (stu, age));</li></ul></li><li><p>unique 唯一索引（唯一约束）<br>使得某字段的值也不能重复。</p></li><li><p>null 约束<br>null不是数据类型，是列的一个属性。<br>表示当前列是否可以为null，表示什么都没有。<br>null, 允许为空。默认。<br>not null, 不允许为空。<br>insert into tab values (null, ‘val’);<br>– 此时表示将第一个字段的值设为null, 取决于该字段是否允许为null</p></li><li><p>default 默认值属性<br>当前字段的默认值。<br>insert into tab values (default, ‘val’); – 此时表示强制使用默认值。<br>create table tab ( add_time timestamp default current_timestamp );<br>– 表示将当前时间的时间戳设为默认值。<br>current_date, current_time</p></li><li><p>auto_increment 自动增长约束<br>自动增长必须为索引（主键或unique）<br>只能存在一个字段为自动增长。<br>默认为1开始自动增长。可以通过表属性 auto_increment = x进行设置，或 alter table tbl auto_increment = x;</p></li><li><p>comment 注释<br>例：create table tab ( id int ) comment ‘注释内容’;</p></li><li><p>foreign key 外键约束<br>用于限制主表与从表数据完整性。<br>alter table t1 add constraint <code>t1_t2_fk</code> foreign key (t1_id) references t2(id);<br>– 将表t1的t1_id外键关联到表t2的id字段。<br>– 每个外键都有一个名字，可以通过 constraint 指定</p><p>存在外键的表，称之为从表（子表），外键指向的表，称之为主表（父表）。</p><p>作用：保持数据一致性，完整性，主要目的是控制存储在外键表（从表）中的数据。</p><p>MySQL中，可以对InnoDB引擎使用外键约束：<br>语法：<br>foreign key (外键字段） references 主表名 (关联字段) [主表记录删除时的动作] [主表记录更新时的动作]<br>此时需要检测一个从表的外键需要约束为主表的已存在的值。外键在没有关联的情况下，可以设置为null.前提是该外键列，没有not null。</p><p>可以不指定主表记录更改或更新时的动作，那么此时主表的操作被拒绝。<br>如果指定了 on update 或 on delete：在删除或更新时，有如下几个操作可以选择：</p><ol><li>cascade，级联操作。主表数据被更新（主键值更新），从表也被更新（外键值更新）。主表记录被删除，从表相关记录也被删除。</li><li>set null，设置为null。主表数据被更新（主键值更新），从表的外键被设置为null。主表记录被删除，从表相关记录外键被设置成null。但注意，要求该外键列，没有not null属性约束。</li><li>restrict，拒绝父表删除和更新。</li></ol><p>注意，外键只被InnoDB存储引擎所支持。其他引擎是不支持的。</p></li></ol><p>/<em> 建表规范 </em>/ ——————<br> – Normal Format, NF</p><ul><li>每个表保存一个实体信息</li><li>每个具有一个ID字段作为主键</li><li>ID主键 + 原子表<br>– 1NF, 第一范式<br>字段不能再分，就满足第一范式。<br>– 2NF, 第二范式<br>满足第一范式的前提下，不能出现部分依赖。<br>消除符合主键就可以避免部分依赖。增加单列关键字。<br>– 3NF, 第三范式<br>满足第二范式的前提下，不能出现传递依赖。<br>某个字段依赖于主键，而有其他字段依赖于该字段。这就是传递依赖。<br>将一个实体信息的数据放在一个表内实现。</li></ul><p>/<em> select </em>/ ——————</p><p>select [all|distinct] select_expr from -&gt; where -&gt; group by [合计函数] -&gt; having -&gt; order by -&gt; limit</p><p>a. select_expr<br> – 可以用 <em> 表示所有字段。<br> select </em> from tb;<br> – 可以使用表达式（计算公式、函数调用、字段也是个表达式）<br> select stu, 29+25, now() from tb;<br> – 可以为每个列使用别名。适用于简化列标识，避免多个列标识符重复。</p><ul><li>使用 as 关键字，也可省略 as.<br>select stu+10 as add10 from tb;</li></ul><p>b. from 子句<br> 用于标识查询来源。<br> – 可以为表起别名。使用as关键字。<br> select <em> from tb1 as tt, tb2 as bb;<br> – from子句后，可以同时出现多个表。<br> – 多个表会横向叠加到一起，而数据会形成一个笛卡尔积。<br> select </em> from tb1, tb2;</p><p>c. where 子句<br> – 从from获得的数据源中进行筛选。<br> – 整型1表示真，0表示假。<br> – 表达式由运算符和运算数组成。<br> – 运算数：变量（字段）、值、函数返回值<br> – 运算符：<br> =, &lt;=&gt;, &lt;&gt;, !=, &lt;=, &lt;, &gt;=, &gt;, !, &amp;&amp;, ||,<br> in (not) null, (not) like, (not) in, (not) between and, is (not), and, or, not, xor<br> is/is not 加上ture/false/unknown，检验某个值的真假<br> &lt;=&gt;与&lt;&gt;功能相同，&lt;=&gt;可用于null比较</p><p>d. group by 子句, 分组子句<br> group by 字段/别名 [排序方式]<br> 分组后会进行排序。升序：ASC，降序：DESC</p><p> 以下[合计函数]需配合 group by 使用：<br> count 返回不同的非NULL值数目 count(*)、count(字段)<br> sum 求和<br> max 求最大值<br> min 求最小值<br> avg 求平均值<br> group_concat 返回带有来自一个组的连接的非NULL值的字符串结果。组内字符串连接。</p><p>e. having 子句，条件子句<br> 与 where 功能、用法相同，执行时机不同。<br> where 在开始时执行检测数据，对原数据进行过滤。<br> having 对筛选出的结果再次进行过滤。<br> having 字段必须是查询出来的，where 字段必须是数据表存在的。<br> where 不可以使用字段的别名，having 可以。因为执行WHERE代码时，可能尚未确定列值。<br> where 不可以使用合计函数。一般需用合计函数才会用 having<br> SQL标准要求HAVING必须引用GROUP BY子句中的列或用于合计函数中的列。</p><p>f. order by 子句，排序子句<br> order by 排序字段/别名 排序方式 [,排序字段/别名 排序方式]…<br> 升序：ASC，降序：DESC<br> 支持多个字段的排序。</p><p>g. limit 子句，限制结果数量子句<br> 仅对处理好的结果进行数量限制。将处理好的结果的看作是一个集合，按照记录出现的顺序，索引从0开始。<br> limit 起始位置, 获取条数<br> 省略第一个参数，表示从索引0开始。limit 获取条数</p><p>h. distinct, all 选项<br> distinct 去除重复记录<br> 默认为 all, 全部记录</p><p>/<em> UNION </em>/ ——————<br> 将多个select查询的结果组合成一个结果集合。<br> SELECT … UNION [ALL|DISTINCT] SELECT …<br> 默认 DISTINCT 方式，即所有返回的行都是唯一的<br> 建议，对每个SELECT查询加上小括号包裹。<br> ORDER BY 排序时，需加上 LIMIT 进行结合。<br> 需要各select查询的字段数量一样。<br> 每个select查询的字段列表(数量、类型)应一致，因为结果中的字段名以第一条select语句为准。</p><p>/<em> 子查询 </em>/ ——————</p><ul><li>子查询需用括号包裹。<br>– from型<br>from后要求是一个表，必须给子查询结果取个别名。</li><li>简化每个查询内的条件。</li><li>from型需将结果生成一个临时表格，可用以原表的锁定的释放。</li><li>子查询返回一个表，表型子查询。<br>select <em> from (select </em> from tb where id&gt;0) as subfrom where id&gt;1;<br>– where型</li><li>子查询返回一个值，标量子查询。</li><li>不需要给子查询取别名。</li><li><p>where子查询内的表，不能直接用以更新。<br>select <em> from tb where money = (select max(money) from tb);<br>– 列子查询<br>如果子查询结果返回的是一列。<br>使用 in 或 not in 完成查询<br>exists 和 not exists 条件<br>如果子查询返回数据，则返回1或0。常用于判断条件。<br>select column1 from t1 where exists (select </em> from t2);<br>– 行子查询<br>查询条件是一个行。<br>select * from t1 where (id, gender) in (select id, gender from t2);<br>行构造符：(col1, col2, …) 或 ROW(col1, col2, …)<br>行构造符通常用于与对能返回两个或两个以上列的子查询进行比较。</p><p>– 特殊运算符<br>!= all() 相当于 not in<br>= some() 相当于 in。any 是 some 的别名<br>!= some() 不等同于 not in，不等于其中某一个。<br>all, some 可以配合其他运算符一起使用。</p></li></ul><p>/<em> 连接查询(join) </em>/ ——————<br> 将多个表的字段进行连接，可以指定连接条件。<br>– 内连接(inner join)</p><ul><li>默认就是内连接，可省略inner。</li><li><p>只有数据存在时才能发送连接。即连接结果不能出现空行。<br>on 表示连接条件。其条件表达式与where类似。也可以省略条件（表示条件永远为真）<br>也可用where表示连接条件。<br>还有 using, 但需字段名相同。 using(字段名)</p><p>– 交叉连接 cross join<br>即，没有条件的内连接。<br>select * from tb1 cross join tb2;<br>– 外连接(outer join)</p></li><li>如果数据不存在，也会出现在连接结果中。<br>– 左外连接 left join<br>如果数据不存在，左表记录会出现，而右表为null填充<br>– 右外连接 right join<br>如果数据不存在，右表记录会出现，而左表为null填充<br>– 自然连接(natural join)<br>自动判断连接条件完成连接。<br>相当于省略了using，会自动查找相同字段名。<br>natural join<br>natural left join<br>natural right join</li></ul><p>select info.id, info.name, info.stu_num, extra_info.hobby, extra_info.sex from info, extra_info where info.stu_num = extra_info.stu_id;</p><p>/<em> 导入导出 </em>/ ——————<br>select * into outfile 文件地址 [控制格式] from 表名; – 导出表数据<br>load data [local] infile 文件地址 [replace|ignore] into table 表名 [控制格式]; – 导入数据<br> 生成的数据默认的分隔符是制表符<br> local未指定，则数据文件必须在服务器上<br> replace 和 ignore 关键词控制对现有的唯一键记录的重复的处理<br>– 控制格式<br>fields 控制字段格式<br>默认：fields terminated by ‘\t’ enclosed by ‘’ escaped by ‘\‘<br> terminated by ‘string’ – 终止<br> enclosed by ‘char’ – 包裹<br> escaped by ‘char’ – 转义<br> – 示例：<br> SELECT a,b,a+b INTO OUTFILE ‘/tmp/result.text’<br> FIELDS TERMINATED BY ‘,’ OPTIONALLY ENCLOSED BY ‘“‘<br> LINES TERMINATED BY ‘\n’<br> FROM test_table;<br>lines 控制行格式<br>默认：lines terminated by ‘\n’<br> terminated by ‘string’ – 终止</p><p>/<em> insert </em>/ ——————<br>select语句获得的数据可以用insert插入。</p><p>可以省略对列的指定，要求 values () 括号内，提供给了按照列顺序出现的所有字段的值。<br> 或者使用set语法。<br> insert into tbl_name set field=value,…；</p><p>可以一次性使用多个值，采用(), (), ();的形式。<br> insert into tbl_name values (), (), ();</p><p>可以在列值指定时，使用表达式。<br> insert into tbl_name values (field_value, 10+10, now());<br>可以使用一个特殊值 default，表示该列使用默认值。<br> insert into tbl_name values (field_value, default);</p><p>可以通过一个查询的结果，作为需要插入的值。<br> insert into tbl_name select …;</p><p>可以指定在插入的值出现主键（或唯一索引）冲突时，更新其他非主键列的信息。<br> insert into tbl_name values/set/select on duplicate key update 字段=值, …;</p><p>/<em> delete </em>/ ——————<br>DELETE FROM tbl_name [WHERE where_definition] [ORDER BY …] [LIMIT row_count]</p><p>按照条件删除</p><p>指定删除的最多记录数。Limit</p><p>可以通过排序条件删除。order by + limit</p><p>支持多表删除，使用类似连接语法。<br>delete from 需要删除数据多表1，表2 using 表连接操作 条件。</p><p>/<em> truncate </em>/ ——————<br>TRUNCATE [TABLE] tbl_name<br>清空数据<br>删除重建表</p><p>区别：<br>1，truncate 是删除表再创建，delete 是逐条删除<br>2，truncate 重置auto_increment的值。而delete不会<br>3，truncate 不知道删除了几条，而delete知道。<br>4，当被用于带分区的表时，truncate 会保留分区</p><p>/<em> 备份与还原 </em>/ ——————<br>备份，将数据的结构与表内数据保存起来。<br>利用 mysqldump 指令完成。</p><p>– 导出</p><ol><li>导出一张表<br>　　mysqldump -u用户名 -p密码 库名 表名 &gt; 文件名(D:/a.sql)</li><li>导出多张表<br>　　mysqldump -u用户名 -p密码 库名 表1 表2 表3 &gt; 文件名(D:/a.sql)</li><li>导出所有表<br>　　mysqldump -u用户名 -p密码 库名 &gt; 文件名(D:/a.sql)</li><li>导出一个库<br>　　mysqldump -u用户名 -p密码 -B 库名 &gt; 文件名(D:/a.sql)</li></ol><p>可以-w携带备份条件</p><p>– 导入</p><ol><li>在登录mysql的情况下：<br>　　source 备份文件</li><li>在不登录的情况下<br>　　mysql -u用户名 -p密码 库名 &lt; 备份文件</li></ol><p>/<em> 视图 </em>/ ——————<br>什么是视图：<br> 视图是一个虚拟表，其内容由查询定义。同真实的表一样，视图包含一系列带有名称的列和行数据。但是，视图并不在数据库中以存储的数据值集形式存在。行和列数据来自由定义视图的查询所引用的表，并且在引用视图时动态生成。<br> 视图具有表结构文件，但不存在数据文件。<br> 对其中所引用的基础表来说，视图的作用类似于筛选。定义视图的筛选可以来自当前或其它数据库的一个或多个表，或者其它视图。通过视图进行查询没有任何限制，通过它们进行数据修改时的限制也很少。<br> 视图是存储在数据库中的查询的sql语句，它主要出于两种原因：安全原因，视图可以隐藏一些数据，如：社会保险基金表，可以用视图只显示姓名，地址，而不显示社会保险号和工资数等，另一原因是可使复杂的查询易于理解和使用。</p><p>– 创建视图<br>CREATE [OR REPLACE] [ALGORITHM = {UNDEFINED | MERGE | TEMPTABLE}] VIEW view_name [(column_list)] AS select_statement</p><ul><li>视图名必须唯一，同时不能与表重名。</li><li>视图可以使用select语句查询到的列名，也可以自己指定相应的列名。</li><li>可以指定视图执行的算法，通过ALGORITHM指定。</li><li>column_list如果存在，则数目必须等于SELECT语句检索的列数</li></ul><p>– 查看结构<br> SHOW CREATE VIEW view_name </p><p>– 删除视图</p><ul><li>删除视图后，数据依然存在。</li><li>可同时删除多个视图。<br>DROP VIEW [IF EXISTS] view_name …</li></ul><p>– 修改视图结构</p><ul><li>一般不修改视图，因为不是所有的更新视图都会映射到表上。<br>ALTER VIEW view_name [(column_list)] AS select_statement</li></ul><p>– 视图作用</p><ol><li>简化业务逻辑</li><li>对客户端隐藏真实的表结构</li></ol><p>– 视图算法(ALGORITHM)<br> MERGE 合并<br> 将视图的查询语句，与外部查询需要先合并再执行！<br> TEMPTABLE 临时表<br> 将视图执行完毕后，形成临时表，再做外层查询！<br> UNDEFINED 未定义(默认)，指的是MySQL自主去选择相应的算法。</p><p>/<em> 事务(transaction) </em>/ ——————<br>事务是指逻辑上的一组操作，组成这组操作的各个单元，要不全成功要不全失败。 </p><ul><li>支持连续SQL的集体成功或集体撤销。</li><li>事务是数据库在数据晚自习方面的一个功能。</li><li>需要利用 InnoDB 或 BDB 存储引擎，对自动提交的特性支持完成。</li><li>InnoDB被称为事务安全型引擎。</li></ul><p>– 事务开启<br> START TRANSACTION; 或者 BEGIN;<br> 开启事务后，所有被执行的SQL语句均被认作当前事务内的SQL语句。<br>– 事务提交<br> COMMIT;<br>– 事务回滚<br> ROLLBACK;<br> 如果部分操作发生问题，映射到事务开启前。</p><p>– 事务的特性</p><ol><li>原子性（Atomicity）<br>事务是一个不可分割的工作单位，事务中的操作要么都发生，要么都不发生。</li><li>一致性（Consistency）<br>事务前后数据的完整性必须保持一致。</li></ol><ul><li>事务开始和结束时，外部数据一致</li><li>在整个事务过程中，操作是连续的</li></ul><ol start="3"><li>隔离性（Isolation）<br>多个用户并发访问数据库时，一个用户的事务不能被其它用户的事物所干扰，多个并发事务之间的数据要相互隔离。</li><li>持久性（Durability）<br>一个事务一旦被提交，它对数据库中的数据改变就是永久性的。</li></ol><p>– 事务的实现</p><ol><li>要求是事务支持的表类型</li><li>执行一组相关的操作前开启事务</li><li>整组操作完成后，都成功，则提交；如果存在失败，选择回滚，则会回到事务开始的备份点。</li></ol><p>– 事务的原理<br> 利用InnoDB的自动提交(autocommit)特性完成。<br> 普通的MySQL执行语句后，当前的数据提交操作均可被其他客户端可见。<br> 而事务是暂时关闭“自动提交”机制，需要commit提交持久化数据操作。</p><p>– 注意</p><ol><li>数据定义语言（DDL）语句不能被回滚，比如创建或取消数据库的语句，和创建、取消或更改表或存储的子程序的语句。</li><li>事务不能被嵌套</li></ol><p>– 保存点<br> SAVEPOINT 保存点名称 – 设置一个事务保存点<br> ROLLBACK TO SAVEPOINT 保存点名称 – 回滚到保存点<br> RELEASE SAVEPOINT 保存点名称 – 删除保存点</p><p>– InnoDB自动提交特性设置<br> SET autocommit = 0|1; 0表示关闭自动提交，1表示开启自动提交。</p><ul><li>如果关闭了，那普通操作的结果对其他客户端也不可见，需要commit提交后才能持久化数据操作。</li><li>也可以关闭自动提交来开启事务。但与START TRANSACTION不同的是，<br>SET autocommit是永久改变服务器的设置，直到下次再次修改该设置。(针对当前连接)<br>而START TRANSACTION记录开启前的状态，而一旦事务提交或回滚后就需要再次开启事务。(针对当前事务)</li></ul><p>/<em> 锁表 </em>/<br>表锁定只用于防止其它客户端进行不正当地读取和写入<br>MyISAM 支持表锁，InnoDB 支持行锁<br>– 锁定<br> LOCK TABLES tbl_name [AS alias]<br>– 解锁<br> UNLOCK TABLES</p><p>/<em> 触发器 </em>/ ——————<br> 触发程序是与表有关的命名数据库对象，当该表出现特定事件时，将激活该对象<br> 监听：记录的增加、修改、删除。</p><p>– 创建触发器<br>CREATE TRIGGER trigger_name trigger_time trigger_event ON tbl_name FOR EACH ROW trigger_stmt<br> 参数：<br> trigger_time是触发程序的动作时间。它可以是 before 或 after，以指明触发程序是在激活它的语句之前或之后触发。<br> trigger_event指明了激活触发程序的语句的类型<br> INSERT：将新行插入表时激活触发程序<br> UPDATE：更改某一行时激活触发程序<br> DELETE：从表中删除某一行时激活触发程序<br> tbl_name：监听的表，必须是永久性的表，不能将触发程序与TEMPORARY表或视图关联起来。<br> trigger_stmt：当触发程序激活时执行的语句。执行多个语句，可使用BEGIN…END复合语句结构</p><p>– 删除<br>DROP TRIGGER [schema_name.]trigger_name</p><p>可以使用old和new代替旧的和新的数据<br> 更新操作，更新前是old，更新后是new.<br> 删除操作，只有old.<br> 增加操作，只有new.</p><p>– 注意</p><ol><li>对于具有相同触发程序动作时间和事件的给定表，不能有两个触发程序。</li></ol><p>– 字符连接函数<br>concat(str1[, str2,…])</p><p>– 分支语句<br>if 条件 then<br> 执行语句<br>elseif 条件 then<br> 执行语句<br>else<br> 执行语句<br>end if;</p><p>– 修改最外层语句结束符<br>delimiter 自定义结束符号<br> SQL语句<br>自定义结束符号</p><p>delimiter ; – 修改回原来的分号</p><p>– 语句块包裹<br>begin<br> 语句块<br>end</p><p>– 特殊的执行</p><ol><li>只要添加记录，就会触发程序。</li><li>Insert into on duplicate key update 语法会触发：<br>如果没有重复记录，会触发 before insert, after insert;<br>如果有重复记录并更新，会触发 before insert, before update, after update;<br>如果有重复记录但是没有发生更新，则触发 before insert, before update</li><li>Replace 语法 如果有记录，则执行 before insert, before delete, after delete, after insert</li></ol><p>/<em> SQL编程 </em>/ ——————</p><p>–// 局部变量 ———-<br>– 变量声明<br> declare var_name[,…] type [default value]<br> 这个语句被用来声明局部变量。要给变量提供一个默认值，请包含一个default子句。值可以被指定为一个表达式，不需要为一个常数。如果没有default子句，初始值为null。 </p><p>– 赋值<br> 使用 set 和 select into 语句为变量赋值。</p><ul><li>注意：在函数内是可以使用全局变量（用户自定义的变量）</li></ul><p>–// 全局变量 ———-<br>– 定义、赋值<br>set 语句可以定义并为变量赋值。<br>set @var = value;<br>也可以使用select into语句为变量初始化并赋值。这样要求select语句只能返回一行，但是可以是多个字段，就意味着同时为多个变量进行赋值，变量的数量需要与查询的列数一致。<br>还可以把赋值语句看作一个表达式，通过select执行完成。此时为了避免=被当作关系运算符看待，使用:=代替。（set语句可以使用= 和 :=）。<br>select @var:=20;<br>select @v1:=id, @v2=name from t1 limit 1;<br>select * from tbl_name where @var:=30;</p><p>select into 可以将表中查询获得的数据赋给变量。<br> -| select max(height) into @max_height from tb;</p><p>– 自定义变量名<br>为了避免select语句中，用户自定义的变量与系统标识符（通常是字段名）冲突，用户自定义变量在变量名前使用@作为开始符号。<br>@var=10;</p><ul><li>变量被定义后，在整个会话周期都有效（登录到退出）</li></ul><p>–// 控制结构 ———-<br>– if语句<br>if search_condition then<br> statement_list<br>[elseif search_condition then<br> statement_list]<br>…<br>[else<br> statement_list]<br>end if;</p><p>– case语句<br>CASE value WHEN [compare-value] THEN result<br>[WHEN [compare-value] THEN result …]<br>[ELSE result]<br>END</p><p>– while循环<br>[begin_label:] while search_condition do<br> statement_list<br>end while [end_label];</p><ul><li><p>如果需要在循环内提前终止 while循环，则需要使用标签；标签需要成对出现。</p><p>– 退出循环<br>退出整个循环 leave<br>退出当前循环 iterate<br>通过退出的标签决定退出哪个循环</p></li></ul><p>–// 内置函数 ———-<br>– 数值函数<br>abs(x) – 绝对值 abs(-10.9) = 10<br>format(x, d) – 格式化千分位数值 format(1234567.456, 2) = 1,234,567.46<br>ceil(x) – 向上取整 ceil(10.1) = 11<br>floor(x) – 向下取整 floor (10.1) = 10<br>round(x) – 四舍五入去整<br>mod(m, n) – m%n m mod n 求余 10%3=1<br>pi() – 获得圆周率<br>pow(m, n) – m^n<br>sqrt(x) – 算术平方根<br>rand() – 随机数<br>truncate(x, d) – 截取d位小数</p><p>– 时间日期函数<br>now(), current_timestamp(); – 当前日期时间<br>current_date(); – 当前日期<br>current_time(); – 当前时间<br>date(‘yyyy-mm-dd hh:ii:ss’); – 获取日期部分<br>time(‘yyyy-mm-dd hh:ii:ss’); – 获取时间部分<br>date_format(‘yyyy-mm-dd hh:ii:ss’, ‘%d %y %a %d %m %b %j’); – 格式化时间<br>unix_timestamp(); – 获得unix时间戳<br>from_unixtime(); – 从时间戳获得时间</p><p>– 字符串函数<br>length(string) – string长度，字节<br>char_length(string) – string的字符个数<br>substring(str, position [,length]) – 从str的position开始,取length个字符<br>replace(str ,search_str ,replace_str) – 在str中用replace_str替换search_str<br>instr(string ,substring) – 返回substring首次在string中出现的位置<br>concat(string [,…]) – 连接字串<br>charset(str) – 返回字串字符集<br>lcase(string) – 转换成小写<br>left(string, length) – 从string2中的左边起取length个字符<br>load_file(file_name) – 从文件读取内容<br>locate(substring, string [,start_position]) – 同instr,但可指定开始位置<br>lpad(string, length, pad) – 重复用pad加在string开头,直到字串长度为length<br>ltrim(string) – 去除前端空格<br>repeat(string, count) – 重复count次<br>rpad(string, length, pad) –在str后用pad补充,直到长度为length<br>rtrim(string) – 去除后端空格<br>strcmp(string1 ,string2) – 逐字符比较两字串大小</p><p>– 流程函数<br>case when [condition] then result [when [condition] then result …] [else result] end 多分支<br>if(expr1,expr2,expr3) 双分支。</p><p>– 聚合函数<br>count()<br>sum();<br>max();<br>min();<br>avg();<br>group_concat()</p><p>– 其他常用函数<br>md5();<br>default();</p><p>–// 存储函数，自定义函数 ———-<br>– 新建<br> CREATE FUNCTION function_name (参数列表) RETURNS 返回值类型<br> 函数体</p><ul><li>函数名，应该合法的标识符，并且不应该与已有的关键字冲突。</li><li>一个函数应该属于某个数据库，可以使用db_name.funciton_name的形式执行当前函数所属数据库，否则为当前数据库。</li><li>参数部分，由”参数名”和”参数类型”组成。多个参数用逗号隔开。</li><li>函数体由多条可用的mysql语句，流程控制，变量声明等语句构成。</li><li>多条语句应该使用 begin…end 语句块包含。</li><li>一定要有 return 返回值语句。</li></ul><p>– 删除<br> DROP FUNCTION [IF EXISTS] function_name;</p><p>– 查看<br> SHOW FUNCTION STATUS LIKE ‘partten’<br> SHOW CREATE FUNCTION function_name;</p><p>– 修改<br> ALTER FUNCTION function_name 函数选项</p><p>–// 存储过程，自定义功能 ———-<br>– 定义<br>存储存储过程 是一段代码（过程），存储在数据库中的sql组成。<br>一个存储过程通常用于完成一段业务逻辑，例如报名，交班费，订单入库等。<br>而一个函数通常专注与某个功能，视为其他程序服务的，需要在其他语句中调用函数才可以，而存储过程不能被其他调用，是自己执行 通过call执行。</p><p>– 创建<br>CREATE PROCEDURE sp_name (参数列表)<br> 过程体</p><p>参数列表：不同于函数的参数列表，需要指明参数类型<br>IN，表示输入型<br>OUT，表示输出型<br>INOUT，表示混合型</p><p>注意，没有返回值。</p><p>/<em> 存储过程 </em>/ ——————<br>存储过程是一段可执行性代码的集合。相比函数，更偏向于业务逻辑。<br>调用：CALL 过程名<br>– 注意</p><ul><li>没有返回值。</li><li>只能单独调用，不可夹杂在其他语句中</li></ul><p>– 参数<br>IN|OUT|INOUT 参数名 数据类型<br>IN 输入：在调用过程中，将数据输入到过程体内部的参数<br>OUT 输出：在调用过程中，将过程体处理完的结果返回到客户端<br>INOUT 输入输出：既可输入，也可输出</p><p>– 语法<br>CREATE PROCEDURE 过程名 (参数列表)<br>BEGIN<br> 过程体<br>END</p><p>/<em> 用户和权限管理 </em>/ ——————<br>用户信息表：mysql.user<br>– 刷新权限<br>FLUSH PRIVILEGES<br>– 增加用户<br>CREATE USER 用户名 IDENTIFIED BY [PASSWORD] 密码(字符串)</p><ul><li>必须拥有mysql数据库的全局CREATE USER权限，或拥有INSERT权限。</li><li>只能创建用户，不能赋予权限。</li><li>用户名，注意引号：如 ‘user_name‘@’192.168.1.1’</li><li>密码也需引号，纯数字密码也要加引号</li><li>要在纯文本中指定密码，需忽略PASSWORD关键词。要把密码指定为由PASSWORD()函数返回的混编值，需包含关键字PASSWORD<br>– 重命名用户<br>RENAME USER old_user TO new_user<br>– 设置密码<br>SET PASSWORD = PASSWORD(‘密码’) – 为当前用户设置密码<br>SET PASSWORD FOR 用户名 = PASSWORD(‘密码’) – 为指定用户设置密码<br>– 删除用户<br>DROP USER 用户名<br>– 分配权限/添加用户<br>GRANT 权限列表 ON 表名 TO 用户名 [IDENTIFIED BY [PASSWORD] ‘password’]</li><li>all privileges 表示所有权限</li><li><em>.</em> 表示所有库的所有表</li><li>库名.表名 表示某库下面的某表<br>– 查看权限<br>SHOW GRANTS FOR 用户名<br>– 查看当前用户权限<br>SHOW GRANTS; 或 SHOW GRANTS FOR CURRENT_USER; 或 SHOW GRANTS FOR CURRENT_USER();<br>– 撤消权限<br>REVOKE 权限列表 ON 表名 FROM 用户名<br>REVOKE ALL PRIVILEGES, GRANT OPTION FROM 用户名 – 撤销所有权限<br>– 权限层级<br>– 要使用GRANT或REVOKE，您必须拥有GRANT OPTION权限，并且您必须用于您正在授予或撤销的权限。<br>全局层级：全局权限适用于一个给定服务器中的所有数据库，mysql.user<br>GRANT ALL ON <em>.</em>和 REVOKE ALL ON <em>.</em>只授予和撤销全局权限。<br>数据库层级：数据库权限适用于一个给定数据库中的所有目标，mysql.db, mysql.host<br>GRANT ALL ON db_name.<em>和REVOKE ALL ON db_name.</em>只授予和撤销数据库权限。<br>表层级：表权限适用于一个给定表中的所有列，mysql.talbes_priv<br>GRANT ALL ON db_name.tbl_name和REVOKE ALL ON db_name.tbl_name只授予和撤销表权限。<br>列层级：列权限适用于一个给定表中的单一列，mysql.columns_priv<br>当使用REVOKE时，您必须指定与被授权列相同的列。<br>– 权限列表<br>ALL [PRIVILEGES] – 设置除GRANT OPTION之外的所有简单权限<br>ALTER – 允许使用ALTER TABLE<br>ALTER ROUTINE – 更改或取消已存储的子程序<br>CREATE – 允许使用CREATE TABLE<br>CREATE ROUTINE – 创建已存储的子程序<br>CREATE TEMPORARY TABLES – 允许使用CREATE TEMPORARY TABLE<br>CREATE USER – 允许使用CREATE USER, DROP USER, RENAME USER和REVOKE ALL PRIVILEGES。<br>CREATE VIEW – 允许使用CREATE VIEW<br>DELETE – 允许使用DELETE<br>DROP – 允许使用DROP TABLE<br>EXECUTE – 允许用户运行已存储的子程序<br>FILE – 允许使用SELECT…INTO OUTFILE和LOAD DATA INFILE<br>INDEX – 允许使用CREATE INDEX和DROP INDEX<br>INSERT – 允许使用INSERT<br>LOCK TABLES – 允许对您拥有SELECT权限的表使用LOCK TABLES<br>PROCESS – 允许使用SHOW FULL PROCESSLIST<br>REFERENCES – 未被实施<br>RELOAD – 允许使用FLUSH<br>REPLICATION CLIENT – 允许用户询问从属服务器或主服务器的地址<br>REPLICATION SLAVE – 用于复制型从属服务器（从主服务器中读取二进制日志事件）<br>SELECT – 允许使用SELECT<br>SHOW DATABASES – 显示所有数据库<br>SHOW VIEW – 允许使用SHOW CREATE VIEW<br>SHUTDOWN – 允许使用mysqladmin shutdown<br>SUPER – 允许使用CHANGE MASTER, KILL, PURGE MASTER LOGS和SET GLOBAL语句，mysqladmin debug命令；允许您连接（一次），即使已达到max_connections。<br>UPDATE – 允许使用UPDATE<br>USAGE – “无权限”的同义词<br>GRANT OPTION – 允许授予权限</li></ul><p>/<em> 表维护 </em>/<br>– 分析和存储表的关键字分布<br>ANALYZE [LOCAL | NO_WRITE_TO_BINLOG] TABLE 表名 …<br>– 检查一个或多个表是否有错误<br>CHECK TABLE tbl_name [, tbl_name] … [option] …<br>option = {QUICK | FAST | MEDIUM | EXTENDED | CHANGED}<br>– 整理数据文件的碎片<br>OPTIMIZE [LOCAL | NO_WRITE_TO_BINLOG] TABLE tbl_name [, tbl_name] …</p><p>/<em> 杂项 </em>/ ——————</p><ol><li>可用反引号（`）为标识符（库名、表名、字段名、索引、别名）包裹，以避免与关键字重名！中文也可以作为标识符！</li><li>每个库目录存在一个保存当前数据库的选项文件db.opt。</li><li>注释：<br>单行注释 # 注释内容<br>多行注释 /<em> 注释内容 </em>/<br>单行注释 – 注释内容 (标准SQL注释风格，要求双破折号后加一空格符（空格、TAB、换行等）)</li><li>模式通配符：<br>_ 任意单个字符<br>% 任意多个字符，甚至包括零字符<br>单引号需要进行转义 \’</li><li>CMD命令行内的语句结束符可以为 “;”, “\G”, “\g”，仅影响显示结果。其他地方还是用分号结束。delimiter 可修改当前对话的语句结束符。</li><li>SQL对大小写不敏感</li><li>清除已有语句：\c</li></ol>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>索引使用策略及优化</title>
      <link href="/2018/05/03/2018-05-03-index/"/>
      <url>/2018/05/03/2018-05-03-index/</url>
      
        <content type="html"><![CDATA[<p>创建索引注意事项：</p><pre><code>在经常查询而不经常增删改操作的字段加索引。order by 与 group by 后应直接使用字段，而且字段应该是索引字段。一个表上的索引不应该超过 6 个。索引字段的长度固定，且长度较短。索引字段重复不能过多，如果某个字段为主键，那么这个字段不用设为索引。在过滤性高的字段上加索引。</code></pre><p>使用索引注意事项：</p><pre><code>使用 like 关键字时，前置 % 会导致索引失效。使用 null 值会被自动从索引中排除，索引一般不会建立在有空值的列上。使用 or 关键字时，or 左右字段如果存在一个没有索引，有索引字段也会失效。使用 != 操作符时，将放弃使用索引。因为范围不确定，使用索引效率不高，会被引擎自动改为全表扫描。不要在索引字段进行运算。在使用复合索引时，最左前缀原则，查询时必须使用索引的第一个字段，否则索引失效；并且应尽量让字段顺序与索引顺序一致。避免隐式转换，定义的数据类型与传入的数据类型保持一致。</code></pre>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>大数据相关概念</title>
      <link href="/2018/03/29/2018-03-29-hadoop/"/>
      <url>/2018/03/29/2018-03-29-hadoop/</url>
      
        <content type="html"><![CDATA[<p>Hadoop  </p><blockquote><p>开源的数据分析平台，解决了大数据（大到一台计算机无法进行存储，一台计算机无法在要求的时间内进行处理）的可靠存储和处理。适合处理非结构化数据，包括HDFS，MapReduce基本组件。  </p></blockquote><blockquote><blockquote><p>分布式系统基础架构，主要由HDFS和MapReduce两部分组成。HDFS（分布式文件存储系统）用于将一个量级巨大的数据存储 在多台 设备上，并有一定的机制保证其完整和容灾，MapReduce则是通过简单的Mapper和Reducer的抽象提供一个编程模型，可以在一个由几十台上 百台的PC组成的不可靠集群上并发地，分布式地处理大量的数据集。</p></blockquote></blockquote><p>Saprk</p><blockquote><p>UCBerkeley AMPlab所开源的类HadoopMapReduce的通用的并行计算框架。新一代的大数据处理引擎，提供分布式内存抽象，以支持工作集的应用。  </p></blockquote><blockquote><blockquote><p>Spark能够运行在现有Hadoop集群之上，但需要依赖于YARN对于资源的调度能力。除了Hadoop YARN之外，Spark还能够以Mesos为基础实现同样的资源调度或者利用自身内置调度程度作为独立集群运行。值得注意的是，如果不将Spark与Hadoop配合使用，那么运行在集群之上时某些网络/分布式文件系统（包括NFS、AFS等）仍然必要，这样每个节点才能够切实访问底层数据。  </p></blockquote></blockquote><blockquote><blockquote><p>运行spark-shell查看spark版本。  </p></blockquote></blockquote><p>Spark与Hadoop的对比(Spark的优势)</p><blockquote><p>1、Spark的中间数据放到内存中，对于迭代运算效率更高<br>2、Spark比Hadoop更通用<br>3、Spark提供了统一的编程接口<br>4、容错性– 在分布式数据集计算时通过checkpoint来实现容错<br>5、可用性– Spark通过提供丰富的Scala, Java，Python API及交互式Shell来提高可用性<br>6、 为Hadoop将每次处理后的数据都写入到磁盘上。Spark的数据对象存储在分布于数据集群中的叫做弹性分布式数据集(RDD:<br>Resilient Distributed Dataset)中。这些数据对象既可以放在内存，也可以放在磁盘。  </p></blockquote><p>Hadoop与Spark的区别 </p><blockquote><p>1、解决问题的层面不一样<br>首先，Hadoop和Apache Spark两者都是大数据框架，但是各自存在的目的不尽相同。Hadoop实质上更多是一个分布式数据基础设施: 它将巨大的数据集分派到一个由普通计算机组成的集群中的多个节点进行存储，意味着您不需要购买和维护昂贵的服务器硬件。同时，Hadoop还会索引和跟踪这些数据，让大数据处理和分析效率达到前所未有的高度。Spark，则是那么一个专门用来对那些分布式存储的大数据进行处理的工具，它并不会进行分布式数据的存储。  </p></blockquote><blockquote><blockquote><p>2、两者可合可分<br>Hadoop除了提供为大家所共识的HDFS分布式数据存储功能之外，还提供了叫做MapReduce的数据处理功能。所以这里我们完全可以抛开Spark，使用Hadoop自身的MapReduce来完成数据的处理。相反，Spark也不是非要依附在Hadoop身上才能生存。但如上所述，毕竟它没有提供文件管理系统，所以，它必须和其他的分布式文件系统进行集 成才能运作。这里我们可以选择Hadoop的HDFS,也可以选择其他的基于云的数据系统平台 。  </p></blockquote></blockquote><p>HDFS</p><blockquote><p>提供了一种跨服务器的弹性数据存储系统。  </p></blockquote><blockquote><blockquote><p>在本质上，NameNode是HDFS的Master(主服务器)，DataNode是Slave(从服务器)。  </p></blockquote></blockquote><blockquote><blockquote><p>NameNode和DataNode:存储到文件系统中的每个文件都有相关联的元数据。元数据包括了文件名、i节点(inode)数、数据块位置等，而数据则是文件的实际内容。其中，元数据存储在NameNode上，而数据存储在DataNode的集群上。  </p></blockquote></blockquote><blockquote><blockquote><p>当一切运行正常时，DataNode会周期性发送心跳信息给NameNode(默认是每3秒钟一次)。如果NameNode在预定的时间内没有收到心跳信息(默认是10分钟)，它会认为DataNode出问题了，把它从集群中移除，并且启动一个进程去恢复数据。对于HDFS来说，丢失一个DataNode意味着丢失了存储在它的硬盘上的数据块的副本。假如在任意时间总有超过一个副本存在(默认3个)，故障将不会导致数据丢失。当一个硬盘故障时，HDFS会检测到存储在该硬盘的数据块的副本数量低于要求，然后主动创建需要的副本，以达到满副本数状态。    </p></blockquote></blockquote><blockquote><blockquote><p>HDFS数据存储单元（block）<br>一、文件被切分成固定大小的文件块<br>1、默认数据大小为64MB，可配置<br>2、若文件大小不到64MB，则单独存储为一个block<br>二、一个文件存储方式<br>1、按大小被切分为若干个block、存储在不同的节点上<br>2、默认情况下每个block都有三个副本  </p></blockquote></blockquote><blockquote><blockquote><p>HDFS不会对用户数据做任何处理，只会存储原文件。不会进行任何压缩处理，唯一做的是多副本存储  </p></blockquote></blockquote><blockquote><blockquote><p>副本存储策略：<br>庞大的HDFS实例一般运行在多个机 架的计算机形成的集群上，不同机架间的两台机器的通讯需要通过交换机，显然通常情况下，同一个机架内的两个节点间的带宽会比不同机架间的两台机器的带宽大。如果数据中心只有一个机架，那么该副本放置策略就退化为一个随机选择策略，数据块的均匀分布和可靠性就很难被保证。<br>通过一个称为Rack Awareness的过程，Namenode决定了每个Datanode所属的rack id。一个简单但没有优化的策略就是将副本存放在单独的机架上。这样可以防止整个机架（非副本存放）失效的情况，并且允许读数据的时候可以从多个机架读 取。这个简单策略设置可以将副本分布在集群中，有利于组件失败情况下的负载均衡。但是，这个简单策略加大了写的代价，因为一个写操作需要传输block到 多个机架。<br>在大多数情况下，replication因子是3，HDFS的存放策略是将一个副本存放在本地机架上的节点，一个副本放在同一机架上的另一个节点，最后一 个副本放在不同机架上的一个节点。机架的错误远远比节点的错误少，这个策略不会影响到数据的可靠性和有效性。三分之一的副本在一个节点上，三分之二在一个 机架上，其他保存在剩下的机架中，这一策略改进了写的性能。  </p></blockquote></blockquote><blockquote><blockquote><p>副本恢复：<br>Namenode启动后会进入一个称为SafeMode的特殊状态，处在这个状态的Namenode是不会进行数据块的复制的。Namenode从所有的 Datanode接收心跳包和Blockreport。Blockreport包括了某个Datanode所有的数据块列表。每个block都有指定的最 小数目的副本。当Namenode检测确认某个Datanode的数据块副本的最小数目，那么该Datanode就会被认为是安全的；如果一定百分比（这 个参数可配置）的数据块检测确认是安全的，那么Namenode将退出SafeMode状态，接下来它会确定还有哪些数据块的副本没有达到指定数目，并将 这些block复制到其他Datanode。  </p></blockquote></blockquote><p>MapReduce</p><blockquote><p>技术提供了感知数据位置的标准化处理流程：读取数据，对数据进行映射（Map），使用某个键值对数据进行重排，然后对数据进行化简（Reduce）得到最终的输出。  </p></blockquote><p>Pig</p><blockquote><p>分析大数据集的一个平台，该平台由一种表达数据分析程序的高级语言和对这些程序进行评估的基础设施一起组成。  </p></blockquote><p>Hive</p><blockquote><p>hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供简单的sql查询功能，可以将sql语句转换为MapReduce任务进行运行。  </p><blockquote><p>Hive跟hbase在功能上也有小部分重叠的地方，它们的主要区别是：Hbase本质是一个数据库，提供在存储层的低延时数据读写能力，可用在实时场景，但没有提供类SQL语言的查询方式，所以数据查询和计算不太方便（PIG学习成本较高）。<br>hive本质是将SQL语句映射成MapReduce作业，延时较高但使用方便，适合离线场景，自身不做存储。此外，hive可以搭建在Hbase之上，访问Hbase的数据。<br>Hive和传统的关系型数据库有很大的区别，Hive将外部的任务解析成一个MapReduce可执行计划，而启动MapReduce是一个高延迟的一件事，每次提交任务和执行任务都需要消耗很多时间，这也就决定Hive只能处理一些高延迟的应用（如果你想处理低延迟的应用，你可以去考虑一下Hbase）。<br>HiveQL和SQL是非常相似的，最主要的区别就是Hive缺少更新和删除功能。<br>Hive就是一款分析历史数据的利器。但是Hive只有在结构化数据的情况下才能大显神威。Hive的软肋是实时分析，如果想要进行实时分析，可以采用HBase。  </p></blockquote></blockquote><p>Hbase</p><blockquote><p>一种分布的、可伸缩的、大数据储存库，支持随机、实时读/写访问。</p></blockquote><blockquote><blockquote><p>HBase 数据库是一个基于分布式的、面向列的、主要用于非结构化数据存储用途的开源数据库。其设计思路来源于 Google 的非开源数据库”BigTable”。<br>HBase作为面向列的数据库运行在HDFS之上，HDFS缺乏随机读写操作，HBase正是为此而出现。如果你需要实时访问一些数据，就把它存入HBase。<br>HDFS 为 HBase 提供底层存储支持，MapReduce 为其提供计算能力，ZooKeeper 为其提供协调服务和 failover（失效转移的备份操作）机制。Pig 和 Hive 为 HBase 提供了高层语言支持，使其可以进行数据统计（可实现多表 join 等），Sqoop 则为其提供 RDBMS 数据导入功能。<br>可以用Hive作为静态数据仓库，HBase作为数据存储，放那些进行一些会改变的数据。<br>Hbase 的模块： 原子性(是指不会被线程调度机制打断的操作，这种操作一旦开始，就一直运行到结束，中间不会有任何contextswitch(切换到领一个线程))，一致性，隔离性，持久性。  </p></blockquote></blockquote><p>Sqoop</p><blockquote><p>为高效传输批量数据而设计的一种工具，其用于Apache Hadoop和结构化数据储存库如关系数据库之间的数据传输。Sqoop则为HBase提供了方便的RDBMS数据导入功能，使得传统数据库数据向HBase中迁移变的非常方便。</p></blockquote><p>Flume</p><blockquote><p>一种分布式的、可靠的、可用的服务，其用于高效地搜集、汇总、移动大量日志数据。</p></blockquote><p>ZooKeeper</p><blockquote><p>一种集中服务，其用于维护配置信息，命名，提供分布式同步，以及提供分组服务。<br>Zookeeper是提供数据同步服务，Yarn和Hbase需要它的支持。</p></blockquote><p>Cloudera</p><blockquote><p>最成型的Hadoop发行版本，拥有最多的部署案例。提供强大的部署、管理和监控工具。开发并贡献了可实时处理大数据的Impala项目。</p></blockquote><p>Hortonworks</p><blockquote><p>使用了100%开源Apache Hadoop提供商。开发了很多增强特性并提交至核心主干，这使得Hadoop能够在包括Windows Server和Azure在内平台上本地运行。</p></blockquote><p>MapR</p><blockquote><p>获取更好的性能和易用性而支持本地Unix文件系统而不是HDFS。提供诸如快照、镜像或有状态的故障恢复等高可用性特性。领导着Apache Drill项目，是Google的Dremel的开源实现，目的是执行类似SQL的查询以提供实时处理。</p></blockquote><p>Impala</p><blockquote><p>Cloudera公司主导开发的新型查询系统，它提供SQL语义，能够查询存储在Hadoop的HDFS和HBase中的PB级大数据，号称比Hive快5-10倍</p><blockquote><p>Impala是对hive的一个补充，可以实现高效的SQL查询。</p></blockquote></blockquote>]]></content>
      
      
      <categories>
          
          <category> 技术篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>使用外部的SMTP发送邮件</title>
      <link href="/2018/03/07/2018-03-28-sendmail/"/>
      <url>/2018/03/07/2018-03-28-sendmail/</url>
      
        <content type="html"><![CDATA[<h3 id="使用外部的SMTP发送邮件"><a href="#使用外部的SMTP发送邮件" class="headerlink" title="使用外部的SMTP发送邮件"></a>使用外部的SMTP发送邮件</h3><h4 id="1、首先是关闭sendmail和postfix"><a href="#1、首先是关闭sendmail和postfix" class="headerlink" title="1、首先是关闭sendmail和postfix"></a>1、首先是关闭sendmail和postfix</h4><p><code>关闭sendmial    service sendmail stop   关闭开机启动  chkconfig sendmail off</code>      </p><p><code>关闭postfix    service postfix stop   关闭开机启动   chkconfig postfix off</code></p><h4 id="2、安装mailx并配置"><a href="#2、安装mailx并配置" class="headerlink" title="2、安装mailx并配置"></a>2、安装mailx并配置</h4><p>ubunut上mailx这个命令对应的deb包有bsd-mailx和heirloom-mailx<br>heirloom-mailx对应的配置文件是/etc/mail.rc。<br>配置过程如下：<br>    第一步：在163邮箱设置–&gt;账户中开启pop3/smtp服务，并记下客户端授权密码  </p><p>第二步：apt-get install heirloom-mailx  </p><p>第三步：vim /etc/mail.rc 在文件最后添加你的邮箱信息:  </p><blockquote><p>(可选1)使用网易SMTP服务（经常被误认为垃圾邮件）：<br>set <a href="mailto:from=150`*`@163.com" target="_blank" rel="noopener">from=150`*`@163.com</a><br>set smtp=smtp.163.com<br>set <a href="mailto:smtp-auth-user=150*@163.com" target="_blank" rel="noopener">smtp-auth-user=150*@163.com</a><br>set smtp-auth-password=Your password  (此处为客户端授权密码，很重要)<br>set smtp-auth-login</p></blockquote><blockquote><p>(可选2)使用QQ邮箱SMTP服务：<br>获取证书文件：<br>mkdir -p /root/.certs/<br>echo -n | openssl s_client -connect 14.18.245.164:465 | sed -ne ‘/-BEGIN CERTIFICATE-/,/-END CERTIFICATE-/p’ &gt; ~/.certs/qq.crt<br>certutil -A -n “GeoTrust SSL CA” -t “C,,” -d ~/.certs -i ~/.certs/qq.crt<br>certutil -A -n “GeoTrust Global CA” -t “C,,” -d ~/.certs -i ~/.certs/qq.crt<br>certutil -L -d /root/.certs<br>mail.rc的配置文件<br>set <a href="mailto:from=150`*`@qq.com" target="_blank" rel="noopener">from=150`*`@qq.com</a><br>set smtp=14.18.245.164<br>set <a href="mailto:smtp-auth-user=150*@qq.com" target="_blank" rel="noopener">smtp-auth-user=150*@qq.com</a><br>set smtp-auth-password=eovkfdykxchfbagf<br>set smtp-auth-login<br>set smtp-use-starttls<br>set ssl-verify=ignore<br>set nss-config-dir=/root/.certs<br>备注：出现“ Error initializing NSS: Unknown error -8015.”是因为用户权限的问题。<br>解决办法：chmod -R 777 /root/.certs<br>qq发信失败代码解释：<a href="http://service.exmail.qq.com/cgi-bin/help?id=20022" target="_blank" rel="noopener">http://service.exmail.qq.com/cgi-bin/help?id=20022</a>  </p></blockquote><p>第四步：直接发送邮件：<br>mailx -s ‘test a mail’ <a href="mailto:277`*`@qq.com" target="_blank" rel="noopener">277`*`@qq.com</a> &lt;0920_check.log  （符号&lt;和文件名之间千万不要有空格，否则会被列为垃圾邮件）</p>]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>oracle导出/导入工具</title>
      <link href="/2018/02/07/2018-06-11-impdp_expdp/"/>
      <url>/2018/02/07/2018-06-11-impdp_expdp/</url>
      
        <content type="html"><![CDATA[<h3 id="1-1-EXPDP-IMPDP-参数说明"><a href="#1-1-EXPDP-IMPDP-参数说明" class="headerlink" title="1.1 EXPDP/IMPDP 参数说明"></a><strong>1.1 EXPDP/IMPDP 参数说明</strong></h3><p>新的导出工具/导入工具也都是命令行工具，调用的方法与传统的导出工具/导入工具相同，新的命令分别是EXPDP和IMPDP。从表面来看，EXPDP/IMPDP 命令与 EXP/IMP 命令最显著的不同就是参数变复杂了！本节将从与 EXP/IMP 命令对比的角度，讲述我在使用新命令（参数）时的一些心得体会。</p><ul><li>userid：无变化，用于指定用户名/口令。依然支持 3 种写法，依然必须是第一个参数，依然可以省略参数名不写。  </li><li>directory：新增，供转储文件和日志文件使用的目录对象。新命令产生的转储文件只能被存放在 directory 对象对应的 OS 目录中，不能直接指定转储文件存放的 OS 目录，因此在执行命令之前需要先创建 directory 对象。如要把转储文件存放在 D 盘的 dump 目录，示例：CREATE OR REPLACE DIRECTORY dump AS ‘D:\dump’;。至少要确保在执行命令时 D 盘存在名为 dump 目录，因为 EXPDP/IMPDP 不会自动创建 OS 目录。很多帖子里都说创建 directory 对象之后还得给导出账户赋读写权限，示例：GRANT READ, WRITE ON DIRECTORY dump TO demo;。我从未这样赋权也能导出！也许是那些帖子抄袭了相同的错误，当然，也可能是我遗漏了什么。事实上，directory 参数有个默认值：DATA_PUMP_DIR（Oracle 预定义的 directory 对象），当不显示给 directory 参数赋值时，就会启用该默认值。可通过 all_directories 视图查询与 DATA_PUMP_DIR 实际映射的 OS 目录。示例：SELECT t.directory_path FROM all_directories t WHERE t.directory_name=’DATA_PUMP_DIR’;。  </li><li>dumpfile：新增，目标转储文件名的列表。若不显示指定，默认值为：EXPDAT.DMP。  </li><li>logfile：新增，日志文件名。若不显示指定，默认值为：export.log。  </li><li>nologfile：新增，不写入日志文件。可选值 y/n，默认为 n，表示写入，即自动在转储文件所在的目录创建日志文件。  </li><li>content：新增，指定要卸载的数据。可选值 all/data_only/metadata_only，默认为 all，表示业务数据和元数据都导出。  </li><li><p>exclude：新增，排除特定类型对象。下面给出几个典型的排除表达式写法供大家参考：<br><code>exclude=statistics</code> 排除统计信息。<br><code>exclude=sequence,trigger</code> 排除序列和触发器。<br><code>exclude=table:\&quot;= &#39;T_STAFF&#39;\&quot; 排除 T_STAFF 表。exclude=table:\&quot;IN (&#39;T_STAFF&#39;,&#39;T_COURSE&#39;)\&quot;</code> 排除 T_STAFF 表和 T_COURSE 表。<br><code>exclude=table:\&quot;&gt; &#39;T&#39;\&quot;</code> 排除开头字母大于 T 的表。<br><code>exclude=procedure:\&quot;LIKE &#39;SP_%&#39;\&quot;</code> 排除以 SP_开头的存储过程。<br><code>exclude=index,view,table:\&quot;= &#39;T_STAFF&#39;\&quot;</code> 排除索引、视图和 T_STAFF 表。  </p></li><li><p>include：新增，包含特定类型对象。参数值表达式写法请参考 exclude 参数。</p></li><li>full：无变化，导出/入整个数据库。可选值 y/n，默认为 n，表示非全库导出/入。</li><li>schemas：相当于 owner，要导出/入的方案的列表。</li><li>tables：无变化，标识要导出/入表的列表。</li><li>query：无变化，用于导出/入表的子集的谓语子句。</li><li>tablespaces：无变化，标识要导出/入表空间的列表。相对来说比较少用。</li><li>estimate：新增，计算作业估计值。可选值 blocks/statistics，默认为 blocks，表示通过数据块数量估算， statistics 表示通过统计信息中记录的内容估算。</li><li>estimate_only：新增（仅导出），在不执行导出的情况下计算作业估计值。</li><li>parallel：更改当前作业活动的 worker 的数目。</li><li>job_name：新增，要创建的导出/入作业的名称。 </li><li>remap_schema：新增（仅导入），将一个方案中的对象加载到另一个方案。</li><li>remap_tablespace：新增（仅导入），讲表空间对象重新映射到另一个表空间。</li><li>table_exists_action：新增（仅导入），导入对象已存在时执行的操作。可选值 skip/append/truncate/replace。默认为 skip，表示跳过。append 表示在原基础上增加数据，truncate 表示先 truncate 表，再插入数据，replace 表示先 drop 表，再创建表并插入数据。</li><li>reuse_datafiles：新增（仅导入），如果表空间已存在，则将其初始化。可选值 y/n，默认为 n。</li><li>sqlfile：新增（仅导入），将所有 DDL 语句写入指定文件。</li></ul><h3 id="1-2-EXPDP-IMPDP-用法示范"><a href="#1-2-EXPDP-IMPDP-用法示范" class="headerlink" title="1.2 EXPDP/IMPDP 用法示范"></a><strong>1.2 EXPDP/IMPDP 用法示范</strong></h3><h4 id="1、全库导出-导入"><a href="#1、全库导出-导入" class="headerlink" title="1、全库导出/导入"></a>1、全库导出/导入</h4><p><code>expdp demo/test directory=dump dumpfile=dat1.dmp logfile=log1.log full=y</code><br><code>impdp demo/test directory=dump dumpfile=dat1.dmp logfile=log1.log full=y</code></p><h4 id="2、按用户导出-导入"><a href="#2、按用户导出-导入" class="headerlink" title="2、按用户导出/导入"></a>2、按用户导出/导入</h4><p><code>expdp demo/test directory=dump dumpfile=dat2.dmp logfile=log2.log schemas=demo</code><br><code>impdp demo/test directory=dump dumpfile=dat2.dmp logfile=log2.log schemas=demo</code>  </p><h4 id="3、按表空间导出-导入"><a href="#3、按表空间导出-导入" class="headerlink" title="3、按表空间导出/导入"></a>3、按表空间导出/导入</h4><p><code>expdp demo/test directory=dump dumpfile=dat3.dmp logfile=log3.log tablespaces=users</code><br><code>impdp demo/test directory=dump dumpfile=dat3.dmp logfile=log3.log tablespaces=users</code></p><h4 id="4、按表导出-导入"><a href="#4、按表导出-导入" class="headerlink" title="4、按表导出/导入"></a>4、按表导出/导入</h4><p><code>expdp demo/test directory=dump dumpfile=dat4.dmp logfile=log4.log tables=t_staff,t_course</code><br><code>impdp demo/test directory=dump dumpfile=dat4.dmp logfile=log4.log tables=t_staff,t_course</code></p><h4 id="5、按查询条件导出-导入"><a href="#5、按查询条件导出-导入" class="headerlink" title="5、按查询条件导出/导入"></a>5、按查询条件导出/导入</h4><p><code>expdp demo/test directory=dump dumpfile=dat5.dmp tables=t_staff query=\&quot; WHERE birthday&gt;=TO_DATE(&#39;1990-01-01&#39;,&#39;yyyy-mm-dd&#39;)\&quot;</code><br><code>impdp demo/test directory=dump dumpfile=dat5.dmp tables=t_staff query=\&quot; WHERE birthday&gt;=TO_DATE(&#39;1990-01-01&#39;,&#39;yyyy-mm-dd&#39;)\&quot;</code></p><h4 id="6、导出-demo-方案，且不写日志"><a href="#6、导出-demo-方案，且不写日志" class="headerlink" title="6、导出 demo 方案，且不写日志"></a>6、导出 demo 方案，且不写日志</h4><p><code>expdp demo/test directory=dump dumpfile=nolog.dmp schemas=demo nologfile=y</code></p><h4 id="7、导出-demo-方案的业务数据"><a href="#7、导出-demo-方案的业务数据" class="headerlink" title="7、导出 demo 方案的业务数据"></a>7、导出 demo 方案的业务数据</h4><p><code>expdp demo/test directory=dump dumpfile=data.dmp logfile=data.log schemas=demo content=data_only</code>  </p><h4 id="8、在不执行导出的情况下，估算-demo-方案"><a href="#8、在不执行导出的情况下，估算-demo-方案" class="headerlink" title="8、在不执行导出的情况下，估算 demo 方案"></a>8、在不执行导出的情况下，估算 demo 方案</h4><p><code>expdp demo/test directory=dump logfile=estimate.log schemas=demo estimate=statistics estimate_only=y</code></p><h4 id="9、导出-t-staff-表定义"><a href="#9、导出-t-staff-表定义" class="headerlink" title="9、导出 t_staff 表定义"></a>9、导出 t_staff 表定义</h4><p><code>expdp demo/test directory=dump dumpfile=staff.dmp logfile=staff.log tables=t_staff content=metadata_only</code> </p><h4 id="10、并行导出-demo-方案，并指定作业名称为-parallel"><a href="#10、并行导出-demo-方案，并指定作业名称为-parallel" class="headerlink" title="10、并行导出 demo 方案，并指定作业名称为 parallel"></a>10、并行导出 demo 方案，并指定作业名称为 parallel</h4><p><code>expdp demo/test directory=dump dumpfile=parallel.dmp logfile=parallel.log schemas=demo parallel=2 job_name=parallel</code></p><h4 id="11、导入前先清空表空间（不可同时指定-reuse-datafiles-和-schemas-或-tablespaces）"><a href="#11、导入前先清空表空间（不可同时指定-reuse-datafiles-和-schemas-或-tablespaces）" class="headerlink" title="11、导入前先清空表空间（不可同时指定 reuse_datafiles 和 schemas 或 tablespaces）"></a>11、导入前先清空表空间（不可同时指定 reuse_datafiles 和 schemas 或 tablespaces）</h4><p><code>impdp demo/test directory=dump dumpfile=dat2.dmp reuse_datafiles=y</code> </p><h4 id="12、按用户导入，且把所有-DLL-语句写入-dat2-sql-文件"><a href="#12、按用户导入，且把所有-DLL-语句写入-dat2-sql-文件" class="headerlink" title="12、按用户导入，且把所有 DLL 语句写入 dat2.sql 文件"></a>12、按用户导入，且把所有 DLL 语句写入 dat2.sql 文件</h4><p><code>impdp demo/test directory=dump dumpfile=dat2.dmp schemas=demo sqlfile=dat2.sql</code>  </p><h4 id="13、也可以把常用的-EXPDP-IMPDP-命令写到批处理文件中，方便日后快速搞定导出-导入。具体操作可参考-EXP-IMP-使用技巧。"><a href="#13、也可以把常用的-EXPDP-IMPDP-命令写到批处理文件中，方便日后快速搞定导出-导入。具体操作可参考-EXP-IMP-使用技巧。" class="headerlink" title="13、也可以把常用的 EXPDP/IMPDP 命令写到批处理文件中，方便日后快速搞定导出/导入。具体操作可参考 EXP/IMP 使用技巧。"></a>13、也可以把常用的 EXPDP/IMPDP 命令写到批处理文件中，方便日后快速搞定导出/导入。具体操作可参考 EXP/IMP 使用技巧。</h4>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Zen of Crack</title>
      <link href="/2018/02/07/2018-02-07-zenofcrack/"/>
      <url>/2018/02/07/2018-02-07-zenofcrack/</url>
      
        <content type="html"><![CDATA[<p>Cracker中的开山鼻祖+ORC是一位身兼工程师与哲学家气质理念的传奇人物，由其撰写的18篇《How to crack》作为最早的破解布道书广为流传，除了纯粹的技术内容外，其中不乏充满灵性的隐喻与哲学理念。在其笔下，令人望而生畏的反编译代码被喻为“代码丛林”(Code wood)，而有幸踏入这块领地的Cracker们则有如苦行于山涧丛林的狩猎者，他们沿着目标所留下的蛛丝马迹苦苦追寻，在坚忍之中等待着正面相遇的那一刻因缘际会。然而完满福德与美好因缘井不会轻易眷顾身带凡夫之气的新手，在他们求得般若之前，也许免不了轮回于一次次触破水月镜花之后的悲喜，迷失于代码丛林时的自我怀疑与望眼欲穿，以及柳暗花明后的唏嘘短叹。Crack的过程对于那些old School(守旧派)来说更像是一次精神修行，帮助你在这旅途中发现自我，找寻一个更好的自我。+ORC在其撰写的教程中不止一次地提及修行的Cracker在Crack之时，不应忘记破解之禅(Zen of Crack)。</p>]]></content>
      
      
      <categories>
          
          <category> 文章摘要 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 文章摘要 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux下查看系统配置常用命令</title>
      <link href="/2017/02/07/Linux%E4%B8%8B%E6%9F%A5%E7%9C%8B%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"/>
      <url>/2017/02/07/Linux%E4%B8%8B%E6%9F%A5%E7%9C%8B%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</url>
      
        <content type="html"><![CDATA[<p>系统<br>  uname -a                 查看内核/操作系统/CPU信息<br>  head -n 1 /etc/issue     查看操作系统版本<br>  cat /proc/cpuinfo        查看CPU信息<br>  hostname                 查看计算机名<br>  lspci -tv                列出所有PCI设备<br>  lsusb -tv                列出所有USB设备<br>  lsmod                    列出加载的内核模块<br>  env                      查看环境变量</p><p>资源<br>  free -m                  查看内存使用量和交换区使用量<br>  df -h                    查看各分区使用情况<br>  du -sh &lt;目录名&gt;          查看指定目录的大小<br>  grep MemTotal /proc/meminfo     查看内存总量<br>  grep MemFree /proc/meminfo      查看空闲内存量<br>  uptime                   查看系统运行时间、用户数、负载<br>  cat /proc/loadavg        查看系统负载</p><p>磁盘和分区<br>  mount | column -t        查看挂接的分区状态<br>  fdisk -l                 查看所有分区<br>  swapon -s                查看所有交换分区<br>  hdparm -i /dev/hda       查看磁盘参数(仅适用于IDE设备)<br>  dmesg | grep IDE         查看启动时IDE设备检测状况</p><p>网络<br>  ifconfig                 查看所有网络接口的属性<br>  iptables -L              查看防火墙设置<br>  route -n                 查看路由表<br>  netstat -lntp            查看所有监听端口<br>  netstat -antp            查看所有已经建立的连接<br>  netstat -s               查看网络统计信息</p><p>进程<br>  ps -ef                   查看所有进程<br>  top                      实时显示进程状态</p><p>用户<br>  w                        查看活动用户<br>  id &lt;用户名&gt;              查看指定用户信息<br>  last                     查看用户登录日志<br>  cut -d: -f1 /etc/passwd     查看系统所有用户<br>  cut -d: -f1 /etc/group      查看系统所有组<br>  crontab -l               查看当前用户的计划任务</p><p>服务<br>  chkconfig –list         列出所有系统服务<br>  chkconfig –list | grep on      列出所有启动的系统服务</p><p>程序</p><p>  rpm -qa                  查看所有安装的软件包</p>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
